{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "from nilearn import plotting, datasets, image\n",
    "from scipy.stats import pearsonr, zscore\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and variables\n",
    "home = '/gpfs/milgram/pi/gee_dylan/candlab/data'\n",
    "hpcdata = home + '/mri/hcp_pipeline_preproc/shapes'\n",
    "taskfiles = home + '/behavioral/shapes/task_design_trialwise'\n",
    "datapath = '/gpfs/milgram/pi/gee_dylan/candlab/analyses/shapes/shapes_phenotyping'\n",
    "recondata = home + '/mri/bids_recon/shapes/*/ses-shapesV1/func'\n",
    "analysis = datapath + '/Analysis'\n",
    "fslpath = '/home/tjk33/project/SHAPES_task_act/out'\n",
    "newri = '/gpfs/milgram/pi/gee_dylan/lms233/RI_Data/coded_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv(analysis + '/subjectlist_n=139_2024-01-29.csv')\n",
    "sublist = pd.DataFrame(list(set(subs['Record ID'].rename('Subject'))), columns = ['Subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72592f-35be-439f-9b34-859e5128a1ae",
   "metadata": {},
   "source": [
    "### Compare across scan data and RI to check for subjects missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RI data\n",
    "rigendate = '2023-04-03' #Validity check on data from Jan 27 \n",
    "\n",
    "ri = pd.read_csv(newri + '/Cleaned_WIDE_all_endorsements_n=191_{}.csv'.format(rigendate), header = 0, index_col=0).set_index('ucla_a_id')\n",
    "ri.columns = 'all_' + (ri.columns).str.lstrip(\"('endorse_any', \").str.rstrip(\")\")\n",
    "ri = ri.reset_index().rename(columns = {'ucla_a_id':'Subject'})\n",
    "ri['Subject'] = 'sub-' + ri['Subject']\n",
    "ri=ri.drop([0], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db247192-a22b-4a2c-97fd-d29b3e4fdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_subs = ri['Subject']\n",
    "print('{} subs have adult RI data'.format(len(ri_subs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9374983-57e4-41f3-b555-130353ecd8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subjects with shapes run 3 data (second testing run)\n",
    "shapes_subs_paths = glob(hpcdata + '/sub-*/MNINonLinear/Results/ses-shapesV1_task-shapes3_bold/ses-shapesV1_task-shapes3_bold_8dv.nii.gz')\n",
    "shapes_subs_full = pd.Series(shapes_subs_paths).str.replace(hpcdata + '/', '', regex=True).str.replace('/MNINonLinear/Results/ses-shapesV1_task-shapes3_bold/ses-shapesV1_task-shapes3_bold_8dv.nii.gz', '', regex=True)\n",
    "print('{} subs have shapes scan data'.format(len(shapes_subs_full)))\n",
    "\n",
    "#Merge with RI data to see\n",
    "has_both = pd.merge(pd.DataFrame(shapes_subs_full, columns=['Subject']), ri_subs, how='inner')\n",
    "print('{} subs have both RI and scan data'.format(len(has_both)))\n",
    "\n",
    "#See who processed\n",
    "proc_subs = pd.Series(glob(fslpath + '/sub-*'), name='Subject').str.replace(fslpath + '/', '')\n",
    "has_proc = pd.merge(pd.DataFrame(proc_subs), has_both)\n",
    "\n",
    "# Identify subjects not currently included\n",
    "union = pd.Series(np.union1d(has_both['Subject'], sublist)) #Compare between globbed result and existing subject list\n",
    "# intersection of the series \n",
    "intersect = pd.Series(np.intersect1d(has_both['Subject'], sublist)) \n",
    "# uncommon elements in both the series  \n",
    "notcommonseries = union[~union.isin(intersect)] \n",
    "# displaying the result \n",
    "print('Not included in both globbed subjectlist and written subjectlist: \\n', notcommonseries) \n",
    "\n",
    "# Identify subjects not currently included\n",
    "union2 = pd.Series(np.union1d(has_both['Subject'], has_proc)) #Compare between globbed result and existing subject list\n",
    "# intersection of the series \n",
    "intersect2 = pd.Series(np.intersect1d(has_both['Subject'], has_proc)) \n",
    "# uncommon elements in both the series  \n",
    "notcommonseries = union2[~union2.isin(intersect2)] \n",
    "print('Not included in both globbed subjectlist and FSL processing: \\n', notcommonseries) \n",
    "\n",
    "# displaying the result \n",
    "## SEE SHAPES CODA TRACKER FOR DETAILED INFORMATION ON WHY EXCLUDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-connecticut",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import demographic data (age at ASR completion and sex at birth)\n",
    "demo_raw = pd.read_csv(analysis + '/Demographics_3.9.22.csv',\n",
    "                       header = 0).rename(columns = {'subj_id':'Subject', \n",
    "                                                     'branch_a_sex':'sex', \n",
    "                                                     'branch_a_gender':'gender',\n",
    "                                                     'maca_a_3':'years_education',\n",
    "                                                     'maca_a_9':'combined_income'})\n",
    "demo = demo_raw[[\"Subject\", \"sex\", 'gender', 'asr_age', \"years_education\", 'combined_income']]\n",
    "demo.loc[:,'combined_income'] = demo.loc[:,'combined_income'].replace([10, 11], np.nan) #Replace don't know and decline to answer with NaN\n",
    "\n",
    "# Read in age at scan\n",
    "aas = pd.read_csv(analysis + '/age_at_scan_2024-04-11.csv', index_col=0)\n",
    "\n",
    "#Diagnostic status\n",
    "diag = pd.read_csv(analysis + '/DiagnosticStatus.csv', \n",
    "                   header = 0).rename(columns = {'record_id':'Subject', 'cc_group':'diagnostic_group'})\n",
    "\n",
    "diag_only = diag[['Subject', 'diagnostic_group']]\n",
    "\n",
    "demo_data = pd.merge(demo, diag_only, how = 'inner', on = 'Subject') #Retain subjects with demog and diag info\n",
    "demo_data = pd.merge(demo_data, aas, on='Subject', how='inner')\n",
    "demo_data.loc[:,'Subject'] = 'sub-' + demo_data.loc[:,'Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only number of endorsements; drop average severity\n",
    "ri_num_ends = ri.iloc[:,0:33].set_index('Subject').replace(np.nan, 0.0)\n",
    "\n",
    "# Code into bins\n",
    "ri_summed = pd.DataFrame(index = ri['Subject'])\n",
    "ri_summed['Early_Childhood'] = np.nansum(ri_num_ends.loc[:,\"all_0.0\":\"all_5.0\"].astype(float), axis=1)\n",
    "ri_summed['Mid_Childhood'] = np.nansum(ri_num_ends.loc[:,\"all_6.0\":\"all_12.0\"].astype(float), axis=1)\n",
    "ri_summed['Adolescence'] = np.nansum(ri_num_ends.loc[:,\"all_13.0\":\"all_17.0\"].astype(float), axis=1)\n",
    "ri_summed['Adulthood'] = np.nansum(ri_num_ends.loc[:,\"all_18.0\":\"all_30.0\"].astype(float), axis=1)\n",
    "ri_summed['Total_Events'] = np.nansum(ri_num_ends.loc[:,\"all_0.0\":\"all_999.0\"].astype(float), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_behav_covariates(df, behav_df):\n",
    "    regressed_output = np.zeros((len(behav_df), len(behav_df.columns)))\n",
    "    \n",
    "    # Create dataframe of regressors -- age at ASR completion, total summed severity of lifetime endorsements, years of education\n",
    "    regressors = df[['age_at_ri_z','sex']]\n",
    "    \n",
    "    # Zscore continuous variables and set categorical variables as factors\n",
    "    regressors = sm.add_constant(regressors) #Add intercept for OLS regression per https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html\n",
    "    \n",
    "    #Run regression\n",
    "    for i in range(0, len(behav_df.columns)):\n",
    "        #Get column name\n",
    "        colname = behav_df.columns[i]\n",
    "        \n",
    "        #Set variables and ensure dtype\n",
    "        col = behav_df.iloc[:,i].astype(float) #Select ith column and confirm float data\n",
    "        assert len(col) == len(behav_df) # Sanity check to make sure selecting from correct axis\n",
    "        print('Mean: ', col.mean())\n",
    "        print('Var: ', col.var())\n",
    "        plt.show()\n",
    "        \n",
    "        # Run Model\n",
    "        model1 = sm.ZeroInflatedNegativeBinomialP(endog = col, exog=regressors, missing = 'raise') # Endog is dependent variable; white matter data; Exog is matrix of regressors\n",
    "        result1 = model1.fit(maxiter = 10000)\n",
    "        regressed_output[:,i] = result1.resid\n",
    "        print(result1.summary())\n",
    "        print('\\nBIC: {}\\n'.format(result1.bic))\n",
    "        # fig, ax = plt.subplots(1,1)\n",
    "        # sns.regplot(col, result1.resid, ax=ax)\n",
    "        plt.show()\n",
    "        sns.histplot(result1.resid)\n",
    "        plt.show()\n",
    "        \n",
    "    regressed_df = pd.DataFrame(regressed_output, columns = behav_df.columns + '_regr')\n",
    "    \n",
    "    return regressed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-batch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge RI and demographic data on subject to ensure alignment\n",
    "ri_demo = pd.merge(demo_data, ri_summed.reset_index(), on='Subject', how = 'inner')\n",
    "print('{} subjects have both RI and diag/demo info'.format(len(ri_demo)))\n",
    "ri_demo = ri_demo.dropna(subset = ['age_at_scan', 'Adulthood', 'sex'])\n",
    "ri_demo['age_at_scan_z'] = zscore(ri_demo['age_at_scan'])\n",
    "ri_demo['age_at_ri_z'] = zscore(ri_demo['age_at_ri'])\n",
    "\n",
    "# Perform regressions\n",
    "ri_bins_regr = regress_behav_covariates(ri_demo, ri_demo.loc[:, \"Early_Childhood\":'Adulthood'])\n",
    "ri_bins_regr = ri_bins_regr.set_index(ri_demo['Subject']).reset_index() #Add subject column back into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf0730-a9e1-4c9a-a5e4-c26edfa19dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize = (20, 5))\n",
    "\n",
    "sns.histplot(x = 'Early_Childhood_regr', data = ri_bins_regr, ax = ax1)\n",
    "sns.histplot(x = 'Mid_Childhood_regr', data = ri_bins_regr, ax = ax2)\n",
    "sns.histplot(x = 'Adolescence_regr', data = ri_bins_regr, ax = ax3)\n",
    "sns.histplot(x = 'Adulthood_regr', data = ri_bins_regr, ax = ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge RI\n",
    "ri_merged = pd.merge(ri_demo, ri_bins_regr, on='Subject')\n",
    "assert len(ri_merged) == len(ri_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and already scored CTQ\n",
    "ctq_scored = pd.read_csv(analysis + '/CTQ_scored.csv')\n",
    "ctq_scored['Subject'] = 'sub-' +  ctq_scored['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Scored ASR Data\n",
    "asr = pd.read_excel(analysis + '/ASR_Scored_Data_1.28.22.xlsx', header = 0, engine = 'openpyxl')\n",
    "asr['Subject']='sub-' + asr['subj_id']\n",
    "\n",
    "asr_small = asr[[\"Subject\", \"Internalizing_Problems_TScore\", \"Internalizing_Problems_Total\", \n",
    "                 \"Total_Problems_TScore\", \"Total_Problems_Total\", \n",
    "                 \"Externalizing_Problems_TScore\", \"Externalizing_Problems_Total\",\n",
    "                \"Anxiety_Problems_Total\", \"Anxiety_Problems_TScore\"]].dropna()\n",
    "print(len(asr_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e3af5-fd57-42eb-aa90-10ad2c433643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RI PTSD data\n",
    "ri_ptsd = pd.read_csv(analysis + '/RI_LMS_PTSD_3.13.24.csv').rename(columns = {'ucla_a_id':'Subject', 'ucla_a_ptsd_p1_rein_31':'ri_ptsd_total'})\n",
    "ri_ptsd['ri_ptsd_total'] = ri_ptsd['ri_ptsd_total'].replace(999,np.nan) # 999 = Missing\n",
    "ri_ptsd['Subject'] = 'sub-' + ri_ptsd['Subject']\n",
    "ri_small = ri_ptsd[[\"Subject\", \"ri_ptsd_total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ICV and data collection site\n",
    "icv = pd.read_csv(analysis + \"/IntracranialVolumes_ScanSites_2024-03-01.csv\").drop('eTIV', axis=1)\n",
    "\n",
    "# Recode scanner site into binary dummy variable\n",
    "icv['site_bin'] = icv['site'].replace('MRRC', 1).replace('BIC', 0).replace('Cedar_300_New_Haven_CT_US_06519', 1) #300 Cedar and MRRC are the same site\n",
    "\n",
    "# Recode subject ID to match other dataframes and clean strings\n",
    "icv['Subject'] = icv['subjectid']\n",
    "icv['Subject'] = icv['Subject'].replace('A616b', 'A616') #Rename; scanner crashed partway through so data sent in two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CDI-RISC data\n",
    "risc = pd.read_csv(analysis + '/QuestionnaireDataCom_DATA_2022-11-07_2003.csv', \n",
    "                   index_col = ['subj_id']).drop(columns = ['cdrisc_complete'], axis=1).dropna(how='any', axis=0)\n",
    "risc['cdirisc_sum'] = np.nansum(risc,axis=1)\n",
    "risc = risc.reset_index().rename(columns = {'subj_id':'Subject'})\n",
    "risc['Subject'] = 'sub-' + risc['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import QA Results\n",
    "qa = pd.read_csv(analysis + '/NeuroimagingQAShapes-Shapes23SummaryResul_DATA_2022-11-07_2025.csv')\n",
    "qa['Subject'] = 'sub-' + qa['qa_subj_id']\n",
    "qa_failed = qa[(qa['qa_s3_ranking'] == 3.0) | (qa['qa_s2_ranking'] == 3.0)]\n",
    "qa_failed_list = list(set('sub-' + pd.Series(qa_failed['qa_subj_id']).str.replace('--1', '').str.replace('--2', '').str.replace('_2', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a546255-07cd-4e41-a4c2-89b74171657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_failed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in subcortical volumes\n",
    "vols = pd.read_csv(analysis + '/Shapes_Subcortical_Volumes_n=207_2024-03-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TSC\n",
    "tsc_full = pd.read_csv(analysis + '/TSC_scored_2024-03-23.csv', index_col=0).set_index('Subject')\n",
    "tsc = tsc_full.dropna(how='all', axis=0).reset_index() #Omit subjects who did not complete TSC\n",
    "tsc['Subject'] = 'sub-' + tsc['Subject']\n",
    "print(len(tsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993eb48-7fa5-4e4e-b70e-d3aa47580978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SCARED\n",
    "scared = pd.read_csv(analysis + '/SCARED_scored_2024-03-23.csv', index_col=0).set_index('Subject')\n",
    "scared = scared.dropna(how='all', axis=0).reset_index()\n",
    "scared['Subject'] = 'sub-' + scared['Subject']\n",
    "print(len(scared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import motion data\n",
    "motion = []\n",
    "\n",
    "for i in range(0, len(sublist)):\n",
    "    try:\n",
    "        sub = sublist.iloc[i][0]\n",
    "        df = pd.read_csv(hpcdata + '/{}/MNINonLinear/Results/Motionstats_summary_allruns.csv'.format(sub), \n",
    "                       sep = '\\t', header=0)\n",
    "        mean_mot2 = df.iloc[0, 15] # Mean FD motion for shapes 2\n",
    "        assert df.columns[15] == ' fdmean_motion_shapes2 '\n",
    "        mean_mot3 = df.iloc[0, 26] # Mean FD motion for shapes 3\n",
    "        assert df.columns[26] == ' fdmean_motion_shapes3 '\n",
    "        mean_both = (mean_mot2 + mean_mot3)/2\n",
    "        motion.append([sub, mean_both])\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print('Error on {}'.format(sub))\n",
    "mot_df = pd.DataFrame(motion, columns = ['Subject', 'mean_fd']).sort_values(by='Subject', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "print(\"Mean: {}\".format(mot_df['mean_fd'].mean()))\n",
    "print(\"Std Dev: {}\".format(mot_df['mean_fd'].std()))\n",
    "print(\"Min: {}\".format(mot_df['mean_fd'].min()))\n",
    "print(\"Max: {}\".format(mot_df['mean_fd'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-edition",
   "metadata": {},
   "source": [
    "**Merge for complete dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_thresh = 0.8\n",
    "mot_uthresh = mot_df[mot_df['mean_fd'] < mot_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.merge(sublist, ri_merged, how = 'inner', on='Subject')\n",
    "print(\"m1: n={}\".format(len(m1)))\n",
    "\n",
    "m2 = pd.merge(m1, scared, how='left', on='Subject')\n",
    "print(\"m2: n={}\".format(len(m2)))\n",
    "\n",
    "m3 = pd.merge(m2, asr_small, how = 'left' )\n",
    "print(\"m3: n={}\".format(len(m3)))\n",
    "\n",
    "m4 = pd.merge(m3, icv, how = 'left' )\n",
    "print(\"m4: n={}\".format(len(m4)))\n",
    "\n",
    "m5 = pd.merge(m4, risc[['Subject', 'cdirisc_sum']], how = 'left')\n",
    "print(\"m5: n={}\".format(len(m5)))\n",
    "\n",
    "m6 = pd.merge(m5, ctq_scored, how='left')\n",
    "print(\"m6: n={}\".format(len(m6)))\n",
    "\n",
    "m7 = pd.merge(m6, mot_uthresh, how='inner')\n",
    "print(\"m7: n={}\".format(len(m7)))\n",
    "\n",
    "m8 = pd.merge(m7, vols, how = 'left', on='Subject')\n",
    "print(\"m8: n={}\".format(len(m8)))\n",
    "\n",
    "m9 = pd.merge(m8, tsc, how='left', on='Subject')\n",
    "print(\"m9: n={}\".format(len(m9)))\n",
    "\n",
    "m10 = pd.merge(m9, ri_small, how = 'left', on='Subject')\n",
    "print(\"m10: n={}\".format(len(m10)))\n",
    "\n",
    "final = m10\n",
    "\n",
    "print('{} subj remaining'.format(len(final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff9600-017c-454a-9eb8-9f4b5f504499",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_failed_list.append('sub-A995')\n",
    "for loc, idx in enumerate(qa_failed_list):\n",
    "    if idx in final['Subject'].tolist():\n",
    "        print('{} in final dataset -- remove'.format(idx))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72159c-2747-4769-ac80-04f4b53a5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop subject that failed QA\n",
    "final = final.set_index('Subject').drop('sub-A647', axis=0).reset_index()\n",
    "final = final.set_index('Subject').drop('sub-A995', axis=0).reset_index()\n",
    "\n",
    "assert 'sub-A647' not in final['Subject'].tolist()\n",
    "assert 'sub-A995' not in final['Subject'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb6bd0-7be3-437f-b8a8-8f87c44ed277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which subs were lost\n",
    "final_check = final\n",
    "final_check['included'] = 1\n",
    "check_df = pd.merge(m1,final_check,  how='outer', on='Subject')\n",
    "\n",
    "remaining = check_df[check_df.included != 1]\n",
    "remaining['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dropped = final.dropna(subset = ['Subject',\n",
    "                                       'age_at_scan', \n",
    "                                       'eTIV', \n",
    "                                       'site_bin', \n",
    "                                       'mean_fd',\n",
    "                                       'Total_Events'], axis=0).sort_values(by='Subject').reset_index(drop=True)\n",
    "\n",
    "final_dropped = final_dropped.set_index('Subject')\n",
    "print(\"{} subjects remaining\".format(len(final_dropped)))\n",
    "\n",
    "outfile = analysis + '/Behav_Dataset_AdulthoodRegr_n={}_{}.csv'.format(len(final_dropped), today)\n",
    "final_dropped.to_csv(outfile)\n",
    "print(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
