{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6029dc-d19e-441f-bdaf-51f3801ceb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "# from netneurotools import cluster\n",
    "# from netneurotools import plotting as nnt_plotting\n",
    "from nipype.interfaces.fsl.maths import BinaryMaths\n",
    "from nipype.interfaces.fsl.utils import ImageMeants\n",
    "import nibabel as nib\n",
    "from stepmix.stepmix import StepMix\n",
    "from nilearn.maskers import NiftiMasker, NiftiLabelsMasker\n",
    "from nilearn import plotting, datasets, image\n",
    "from sklearn.linear_model import RidgeClassifier, ElasticNet, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from statistics import mode\n",
    "from scipy.stats import kruskal, pearsonr, spearmanr, zscore\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "today=str(date.today())\n",
    "\n",
    "sns.set_palette('Paired')\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and variables\n",
    "home = '/gpfs/milgram/pi/gee_dylan/candlab/data'\n",
    "hcpdata = home + '/mri/hcp_pipeline_preproc/shapes'\n",
    "taskfiles = home + '/behavioral/shapes/task_design_trialwise'\n",
    "datapath = '/gpfs/milgram/pi/gee_dylan/candlab/analyses/shapes/shapes_phenotyping'\n",
    "fslpath = '/home/tjk33/project/SHAPES_task_act/out'\n",
    "analysis = datapath + '/Analysis'\n",
    "suffix = 'bold_8dv_resampled.nii.gz'\n",
    "plt_out = analysis + '/Figures'\n",
    "rois = '/gpfs/milgram/pi/gee_dylan/candlab/atlases/Mackey_vmPFC/VmPFC_symmetric_LMS/bin_niftis'\n",
    "\n",
    "bv_df_orig = pd.read_csv(analysis + '/Behav_Dataset_n=131_2024-06-21.csv')\n",
    "subjects = bv_df_orig['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to categorical and standardize in behav df\n",
    "bv_df_orig['sex'] = bv_df_orig['sex'].astype('category')\n",
    "bv_df_orig['cdirisc_sum_z'] = zscore(bv_df_orig['cdirisc_sum'], nan_policy='omit')\n",
    "bv_df_orig['years_education'] = bv_df_orig['years_education'].astype('category')\n",
    "bv_df_orig['combined_income'] = bv_df_orig['combined_income'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec9fac-2da7-4c63-bbbf-304b63b5273e",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4316573-13b2-42f5-9524-b70310ad8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function using FSL tools via Nipype to average the two contrasts (runs 2 and 3) together\n",
    "def avg_copes(sub, cope):\n",
    "    if os.path.exists(datapath + '/{}/{}_{}_cope_averaged.nii.gz'.format(sub, sub, cope)):\n",
    "            threat_cope = nib.load(datapath + '/{}/{}_{}_cope_averaged.nii.gz'.format(sub, sub, cope))\n",
    "    else:\n",
    "        BinaryMaths(in_file=fslpath + '/{}/testing_1/main.feat/stats/{}_cope.nii.gz'.format(sub, cope),\n",
    "                          operand_file = fslpath + '/{}/testing_2/main.feat/stats/{}_cope.nii.gz'.format(sub, cope),\n",
    "                          operation = 'add',\n",
    "                          out_file = datapath + '/{}/{}_{}_cope_added.nii.gz'.format(sub, sub, cope)).run()\n",
    "        \n",
    "        BinaryMaths(in_file = datapath + '/{}/{}_{}_cope_added.nii.gz'.format(sub, sub, cope),\n",
    "                   operand_value = 2,\n",
    "                   operation = 'div',\n",
    "                   out_file = datapath + '/{}/{}_{}_cope_averaged.nii.gz'.format(sub, sub, cope)).run()\n",
    "    \n",
    "    \n",
    "    threat_cope_file = datapath + '/{}/{}_{}_cope_averaged.nii.gz'.format(sub, sub, cope)\n",
    "    threat_cope = nib.load(threat_cope_file)\n",
    "    \n",
    "    return threat_cope_file, threat_cope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913af041-6a3b-4c4f-a103-30349896b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get global mean of contrasts\n",
    "def get_global_mean(sub, cope):\n",
    "    # Load in copes\n",
    "    cope_img1 = nib.load(fslpath + '/{}/testing_1/main.feat/stats/{}_cope.nii.gz'.format(sub, cope))\n",
    "    cope_img2 = nib.load(fslpath + '/{}/testing_2/main.feat/stats/{}_cope.nii.gz'.format(sub, cope))\n",
    "    copes_concat = np.concatenate([cope_img1.dataobj, cope_img2.dataobj], axis=2) # Concatenate along an axis\n",
    "    \n",
    "    #Compute means\n",
    "    m1 = np.nanmean(copes_concat, axis=1)\n",
    "    m2 = np.nanmean(m1, axis=1)\n",
    "    mean_val = np.nanmean(m2) # Double checked this is correcct in FSL and with avg_copes function\n",
    "    return mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2fac1-a501-45ba-8f71-5d0e2d91a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_parcellate(sub, cope, cope_name, cope_mean, roi_file_list, names_list, demean, uniqueid):\n",
    "    \n",
    "    #Average runs 1 and 2 together\n",
    "    cope_coefs_orig_file, cope_coefs_orig = avg_copes(sub, cope)\n",
    "\n",
    "    if demean == True:\n",
    "        print('Demeaning the data')\n",
    "        # Demean the data\n",
    "        cope_coefs_demeaned = cope_coefs_orig.get_fdata(caching='unchanged') \n",
    "        cope_coefs_demeaned[:, :, :] = cope_coefs_demeaned[:, :, :] - cope_mean #Will cache and update .dataobj in place\n",
    "        cope_coefs = nib.Nifti1Image(cope_coefs_demeaned, cope_coefs_orig.affine)\n",
    "        cope_coefs_demeaned_abs = np.absolute(cope_coefs_demeaned)\n",
    "        cope_coefs_abs = nib.Nifti1Image(cope_coefs_demeaned_abs, cope_coefs_orig.affine)\n",
    "        \n",
    "        assert (cope_coefs_orig.get_fdata(caching='unchanged').all == cope_coefs_demeaned.all) == False\n",
    "        assert (cope_coefs_demeaned.all == cope_coefs_demeaned_abs.all) == False\n",
    "        \n",
    "    else:\n",
    "        cope_coefs = cope_coefs_orig\n",
    "        cope_coefs_data_abs = np.absolute(cope_coefs_orig.get_fdata(caching='unchanged'))\n",
    "        cope_coefs_abs = nib.Nifti1Image(cope_coefs_data_abs, cope_coefs_orig.affine)\n",
    "    \n",
    "    # Loop through ROIs list\n",
    "    parc_cope = dict(left_hippocampus_Shen368 = [],\n",
    "                      right_hippocampus_Shen368 = [],\n",
    "                      left_amygdala_Shen368 = [],\n",
    "                      right_amygdala_Shen368 = [],\n",
    "                      Mackey_area14m_left = [],\n",
    "                      Mackey_area14m_right = [],\n",
    "                      Mackey_area24_left = [],\n",
    "                      Mackey_area24_right = [],\n",
    "                      Mackey_area25_left = [],\n",
    "                      Mackey_area25_right = [],\n",
    "                      Mackey_area32_left = [],\n",
    "                      Mackey_area32_right = [])\n",
    "    parc_cope_abs = deepcopy(parc_cope) \n",
    "    \n",
    "    for j in range(0, len(roi_file_list)):\n",
    "        \n",
    "        roi=roi_file_list[j]\n",
    "        name = names_list[j]\n",
    "        print('Extracting data for {} {}...'.format(cope, name))\n",
    "\n",
    "        ImageMeants(in_file=cope_coefs_orig_file,\n",
    "                    mask = roi,\n",
    "                    out_file = datapath + '/{}/{}_{}_{}_cope_meants.txt'.format(sub, sub, cope, name),\n",
    "                    terminal_output = 'stream').run()\n",
    "\n",
    "        cope_parc = pd.read_csv(datapath + '/{}/{}_{}_{}_cope_meants.txt'.format(sub, sub, cope, name),\n",
    "                               sep = ' ', header=None).iloc[0,0]\n",
    "        assert cope_parc != np.nan\n",
    "        assert cope_parc != 0\n",
    "        \n",
    "        if len(roi_file_list) > 1:\n",
    "            # Append output\n",
    "            parc_cope[name].append(cope_parc)\n",
    "            \n",
    "        else:\n",
    "            parc_cope = cope_parc\n",
    "        \n",
    "    return parc_cope \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477d253-c75e-40a4-8510-dfbff4333233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcellate_shen(sub, cope, cope_name, cope_mean, roi_file_list, names_list, demean, uniqueid):\n",
    "    \n",
    "    #Average runs 1 and 2 together\n",
    "    cope_coefs_orig_file, cope_coefs_orig = avg_copes(sub, cope)\n",
    "\n",
    "    if demean == True:\n",
    "        print('Demeaning the data')\n",
    "        # Demean the data\n",
    "        cope_coefs_demeaned = cope_coefs_orig.get_fdata(caching='unchanged') \n",
    "        cope_coefs_demeaned[:, :, :] = cope_coefs_demeaned[:, :, :] - cope_mean #Will cache and update .dataobj in place\n",
    "        cope_coefs = nib.Nifti1Image(cope_coefs_demeaned, cope_coefs_orig.affine)\n",
    "        cope_coefs_demeaned_abs = np.absolute(cope_coefs_demeaned)\n",
    "        cope_coefs_abs = nib.Nifti1Image(cope_coefs_demeaned_abs, cope_coefs_orig.affine)\n",
    "        \n",
    "        assert (cope_coefs_orig.get_fdata(caching='unchanged').all == cope_coefs_demeaned.all) == False\n",
    "        assert (cope_coefs_demeaned.all == cope_coefs_demeaned_abs.all) == False\n",
    "        \n",
    "    else:\n",
    "        cope_coefs = cope_coefs_orig\n",
    "        cope_coefs_data_abs = np.absolute(cope_coefs_orig.get_fdata(caching='unchanged'))\n",
    "        cope_coefs_abs = nib.Nifti1Image(cope_coefs_data_abs, cope_coefs_orig.affine)\n",
    "    \n",
    "    for loc, roi in enumerate(roi_file_list):\n",
    "        name = names_list[loc]\n",
    "        \n",
    "        print('Parcellating {}'.format(name))\n",
    "        raw_file1 = nib.load(datapath + '/{}/{}_task-shapes2_bold_8dv.nii.gz'.format(sub, sub))\n",
    "        \n",
    "        # Intialize masker\n",
    "        masker = NiftiLabelsMasker(labels_img=roi, resampling_target=None, standardize=False, detrend=False)\n",
    "        masker.fit(cope_coefs) #Fit on raw file\n",
    "    \n",
    "        print(cope_coefs.shape)\n",
    "    \n",
    "        # Apply our atlas to the Nifti object so we can pull out data from single parcels/ROIs\n",
    "        cope_parc = masker.transform(cope_coefs) # Transform residuals\n",
    "        \n",
    "        #Transform absolute values\n",
    "        cope_parc_abs = masker.transform(cope_coefs_abs) # Transform residuals abs value\n",
    "        \n",
    "        cope_parc_brain = masker.inverse_transform(cope_parc)\n",
    "        nib.save(cope_parc_brain, datapath + '/{}/Shapes_{}Cope_{}_{}.nii.gz'.format(sub, cope_name, name, unique_id))\n",
    "        \n",
    "        # Plot  parcellation\n",
    "        html_view = plotting.plot_roi(cope_parc_brain, # threshold=2, vmax=4,\n",
    "                                      colorbar=True,\n",
    "                                      title=\"Parcellated data for {}\".format(sub))\n",
    "        plt.show()\n",
    "        if len(roi_file_list) > 1:\n",
    "            # Append output\n",
    "            parc_cope[name].append(cope_parc)\n",
    "            \n",
    "        else:\n",
    "            parc_cope = cope_parc\n",
    "            # parc_cope_abs = cope_parc_abs\n",
    "        \n",
    "    return parc_cope #, parc_cope_abs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377be9f7-2d68-486d-becb-2b92f719cddd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Compute whole-brain means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284193af-7a54-432f-b403-7f6f5c6cbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amin_means = []\n",
    "# bmin_means = []\n",
    "# amin_bmin_means = []\n",
    "\n",
    "# for i in range(0, len(subjects)):\n",
    "#     sub = subjects[i]\n",
    "#     amin_mean = get_global_mean(sub, 'AMINUS')\n",
    "#     bmin_mean = get_global_mean(sub, 'BMINUS')\n",
    "#     amin_bmin = get_global_mean(sub, 'AMINUS-BMINUS')\n",
    "\n",
    "#     amin_means.append([sub, amin_mean])\n",
    "#     bmin_means.append([sub, bmin_mean])\n",
    "#     amin_bmin_means.append([sub, amin_bmin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01a59d-5672-4618-a943-068e29adf066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threat_means = pd.DataFrame(amin_means, columns = ['Subject', 'aminus_mean_act'])\n",
    "# safety_means = pd.DataFrame(bmin_means, columns = ['Subject', 'bminus_mean_act'])\n",
    "# tvs_means = pd.DataFrame(amin_bmin_means, columns = ['Subject', 'aminus-bminus_mean_act'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3261e1-6372-4f8e-9db7-e1437abbabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write means to CSV\n",
    "# threat_means.to_csv(analysis + '/ThreatVsBaseline_WholeBrain_MeanActivation_n={}_{}.csv'.format(len(threat_means), today))\n",
    "# safety_means.to_csv(analysis + '/SafetyVsBaseline_WholeBrain_MeanActivation_n={}_{}.csv'.format(len(safety_means), today))\n",
    "# tvs_means.to_csv(analysis + '/ThreatVsSafety_WholeBrain_MeanActivation_n={}_{}.csv'.format(len(tvs_means), today))\n",
    "# print(analysis + '/ThreatVsSafety_WholeBrain_MeanActivation_n={}_{}.csv'.format(len(tvs_means), today))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc344d-bab2-4723-91c0-7aadac57c91d",
   "metadata": {},
   "source": [
    "### Read in whole-brain means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38011215-78e0-4e10-818c-3e5cb85760c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Set unique identifier for this round of parcellations ***\n",
    "unique_id = today + '_NotDemeaned'\n",
    "# *************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b163e-a5a8-4bd4-b6fe-d360f4643d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in means from date when computed\n",
    "means_date = '2024-06-21'\n",
    "\n",
    "threat_means = pd.read_csv(analysis + '/ThreatVsBaseline_WholeBrain_MeanActivation_n=131_{}.csv'.format(means_date), index_col=0)\n",
    "safety_means = pd.read_csv(analysis + '/SafetyVsBaseline_WholeBrain_MeanActivation_n=131_{}.csv'.format(means_date), index_col=0)\n",
    "tvs_means = pd.read_csv(analysis + '/ThreatVsSafety_WholeBrain_MeanActivation_n=131_{}.csv'.format(means_date), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-ladder",
   "metadata": {},
   "source": [
    "### Parcellate Mackey ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99256bf6-1c03-487e-a379-eca9d6fd4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define files list\n",
    "vmpfc_files = glob(rois + '/left*resampled.nii.gz') + glob(rois + '/right*resampled.nii.gz') + glob(rois + '/*area14m_*resampled.nii.gz') + glob(rois + '/*area24_*resampled.nii.gz') + glob(rois + '/*area25_*resampled.nii.gz') + glob(rois + '/*area32_*resampled.nii.gz')\n",
    "\n",
    "ho_dacc_files = glob(rois + '/HarvardOxford_dACC*.nii.gz')\n",
    "aal_dacc_files = glob(rois + '/AAL3_dACC*.nii.gz')\n",
    "\n",
    "# Define names list\n",
    "vmpfc_names = pd.Series(vmpfc_files).str.replace(rois + '/','', regex=True).str.replace('_MNI_bin', '', regex=True).str.replace('.nii.gz', '', regex=True).str.replace('1_symmetric', 'Mackey', regex=True).str.replace('_resampled', '')\n",
    "\n",
    "ho_dacc_names = pd.Series(ho_dacc_files).str.replace(rois + '/','', regex=True).str.replace('_maxprob_thr0_2mm_Binarized', '', regex=True).str.replace('.nii.gz', '', regex=True)\n",
    "\n",
    "aal_dacc_names = pd.Series(aal_dacc_files).str.replace(rois + '/','', regex=True).str.replace('_156_bilat_bin', '', regex=True).str.replace('.nii.gz', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e2696-a717-40f9-9eaa-5d97ffc7a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmpfc_dict = dict(left_amygdala_Shen368 = [],\n",
    "                  left_hippocampus_Shen368 = [],\n",
    "                  right_amygdala_Shen368 = [],\n",
    "                  right_hippocampus_Shen368 = [],\n",
    "                  Mackey_area14m_left = [],\n",
    "                  Mackey_area14m_right = [],\n",
    "                  Mackey_area24_left = [],\n",
    "                  Mackey_area24_right = [],\n",
    "                  Mackey_area25_left = [],\n",
    "                  Mackey_area25_right = [],\n",
    "                  Mackey_area32_left = [],\n",
    "                  Mackey_area32_right = [])\n",
    "\n",
    "ho_dacc_dict = dict(HarvardOxford_dACC = [])\n",
    "aal_dacc_dict = dict(AAL3_dACC=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3354c11-815f-4dca-a4eb-47c8df72224e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run function for all subjects\n",
    "\n",
    "# ********* Define dict we want to run function for *********\n",
    "roi_dict = vmpfc_dict\n",
    "names_func_list = vmpfc_names\n",
    "files_func_list = vmpfc_files\n",
    "# ***********************************************************\n",
    "\n",
    "subjects_added = []\n",
    "parc_threat = deepcopy(roi_dict) \n",
    "parc_threat_abs = deepcopy(roi_dict) \n",
    "parc_safety = deepcopy(roi_dict)\n",
    "parc_safety_abs = deepcopy(roi_dict)\n",
    "parc_tvs = deepcopy(roi_dict)\n",
    "parc_tvs_abs = deepcopy(roi_dict)\n",
    "subs_added = []\n",
    "\n",
    "for loc, sub in enumerate(subjects):\n",
    "    print('*** Starting {}... ***'.format(sub))\n",
    "    # Get means\n",
    "    threat_mean = threat_means[threat_means['Subject'] == sub]['aminus_mean_act'].iloc[0]\n",
    "    safety_mean = safety_means[safety_means['Subject'] == sub]['bminus_mean_act'].iloc[0]\n",
    "    tvs_mean = tvs_means[tvs_means['Subject'] == sub]['aminus-bminus_mean_act'].iloc[0]\n",
    "\n",
    "    # Run function\n",
    "    threat_parc = process_parcellate(sub, 'AMINUS', 'ThreatVsBaseline', threat_mean, files_func_list, names_func_list, demean=False, uniqueid = unique_id)\n",
    "    safety_parc = process_parcellate(sub, 'BMINUS', 'SafetyVsBaseline', safety_mean, files_func_list, names_func_list, demean=False, uniqueid = unique_id)\n",
    "    tvs_parc = process_parcellate(sub, 'AMINUS-BMINUS', 'ThreatVsSafety', tvs_mean, files_func_list, names_func_list, demean=False, uniqueid = unique_id)\n",
    "    \n",
    "    for loc, name in enumerate(names_func_list):\n",
    "        parc_threat[name].append(threat_parc[name][0]) #[name][0]\n",
    "        # parc_threat_abs[name].append(threat_parc_abs[name])\n",
    "        parc_safety[name].append(safety_parc[name][0]) #[name][0]\n",
    "        # parc_safety_abs[name].append(safety_parc_abs[name])\n",
    "        parc_tvs[name].append(tvs_parc[name][0]) #[name][0]\n",
    "        # parc_tvs_abs[name].append(tvs_parc_abs[name])\n",
    "        subs_added.append(sub)                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a991ea-9bc9-4041-ab90-d5bb65f9340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subswdata = pd.Series(pd.Series(subs_added).unique(), name='Subject', dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b316929-a784-4bdc-a76b-abf24b2e4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_data = pd.concat([subswdata,pd.DataFrame(parc_threat)], axis=1)\n",
    "safety_data = pd.concat([subswdata,pd.DataFrame(parc_safety)], axis=1)\n",
    "tvs_data= pd.concat([subswdata,pd.DataFrame(parc_tvs)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74806a0-f956-43e8-9045-87cdb1e80d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distributions of parcellated data\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "sns.distplot(threat_data.iloc[:, 1], ax = ax1)\n",
    "sns.distplot(safety_data.iloc[:, 1], ax = ax2)\n",
    "sns.distplot(tvs_data.iloc[:, 1], ax = ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f40be-b081-4604-a058-835326d8779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "if roi_dict == vmpfc_dict:\n",
    "    thr_file = analysis + '/ThreatVsBaseline_Subcortical_Mackey_vmPFC_CopeData_n={}_{}.csv'.format(len(threat_data), unique_id)\n",
    "    threat_data.to_csv(thr_file)\n",
    "    saf_file = analysis + '/SafetyVsBaseline_Subcortical_Mackey_vmPFC_CopeData_n={}_{}.csv'.format(len(safety_data), unique_id)\n",
    "    safety_data.to_csv(saf_file)\n",
    "    tvs_file = analysis + '/ThreatVsSafety_Subcortical_Mackey_vmPFC_CopeData_n={}_{}.csv'.format(len(threat_data), unique_id)\n",
    "    tvs_data.to_csv(tvs_file)\n",
    "elif roi_dict == ho_dacc_dict:\n",
    "    thr_file = analysis + '/ThreatVsBaseline_Subcortical_HarvardOxford_dACC_CopeData_n={}_{}.csv'.format(len(threat_data), unique_id)\n",
    "    threat_data.to_csv(thr_file)\n",
    "    saf_file = analysis + '/SafetyVsBaseline_Subcortical_HarvardOxford_dACC_CopeData_n={}_{}.csv'.format(len(safety_data), unique_id)\n",
    "    safety_data.to_csv(saf_file)\n",
    "    tvs_file = analysis + '/ThreatVsSafety_Subcortical_HarvardOxford_dACC_CopeData_n={}_{}.csv'.format(len(threat_data), unique_id)\n",
    "    tvs_data.to_csv(tvs_file)\n",
    "elif roi_dict == aal_dacc_dict:\n",
    "    thr_file = analysis + '/ThreatVsBaseline_Subcortical_AAL3_dACC_CopeData_n={}_{}.csv'.format(len(threat_data), unique_id)\n",
    "    threat_data.to_csv(thr_file)\n",
    "    saf_file = analysis + '/SafetyVsBaseline_Subcortical_AAL3_dACC_CopeData_n={}_{}.csv'.format(len(safety_data), unique_id)\n",
    "    safety_data.to_csv(saf_file)\n",
    "    tvs_file = analysis + '/ThreatVsSafety_Subcortical_AAL3_dACC_CopeData_n={}_{}.csv'.format(len(threat_data), unique_id)\n",
    "    tvs_data.to_csv(tvs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfbd37-3058-4968-a608-fe37af508584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thr_file)\n",
    "print(saf_file)\n",
    "print(tvs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c086a5-be1a-4483-826f-72ee2d81648e",
   "metadata": {},
   "source": [
    "### Parcellate Shen Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e7482-0bcc-479e-b539-a15ca6bb175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shen 368 atlas\n",
    "atlas = nib.load('/gpfs/milgram/pi/gee_dylan/lms233/Shen368/Shen_1mm_368_parcellation_resampled.nii.gz')\n",
    "shen_filename = ['/gpfs/milgram/pi/gee_dylan/lms233/Shen368/Shen_1mm_368_parcellation_resampled.nii.gz']\n",
    "\n",
    "shen_names = ['Shen368']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25e621-5111-4aec-91eb-bf4c48a9008e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs_date_shen = '2024-02-11'\n",
    "subjects_loaded = []\n",
    "parc_threat_shen = np.zeros((len(subjects), 368))\n",
    "parc_safety_shen = np.zeros((len(subjects), 368))\n",
    "parc_tvs_shen = np.zeros((len(subjects), 368))\n",
    "parc_threat_shen_abs = np.zeros((len(subjects), 368))\n",
    "parc_safety_shen_abs = np.zeros((len(subjects), 368))\n",
    "parc_tvs_shen_abs = np.zeros((len(subjects), 368))\n",
    "\n",
    "for i in range(0, len(subjects)):\n",
    "    sub = subjects[i]\n",
    "    print('Starting {}...'.format(sub))\n",
    "    # Get means\n",
    "    threat_mean = threat_means[threat_means['Subject'] == sub]['aminus_mean_act'].iloc[0]\n",
    "    safety_mean = safety_means[safety_means['Subject'] == sub]['bminus_mean_act'].iloc[0]\n",
    "    tvs_mean = tvs_means[tvs_means['Subject'] == sub]['aminus-bminus_mean_act'].iloc[0]\n",
    "\n",
    "    # Run function\n",
    "    threat_parc_shen = parcellate_shen(sub, 'AMINUS', 'ThreatVsBaseline', threat_mean, shen_filename, shen_names, demean=False, uniqueid = today + '_NotDemeaned')\n",
    "    safety_parc_shen = parcellate_shen(sub, 'BMINUS', 'SafetyVsBaseline', safety_mean, shen_filename, shen_names, demean=False, uniqueid = today + '_NotDemeaned')\n",
    "    tvs_parc_shen = parcellate_shen(sub, 'AMINUS-BMINUS', 'ThreatVsSafety', tvs_mean, shen_filename, shen_names, demean=False, uniqueid = today + '_NotDemeaned')\n",
    "\n",
    "    # Save output\n",
    "    parc_threat_shen[i,:] = threat_parc_shen \n",
    "    parc_safety_shen[i,:] = safety_parc_shen \n",
    "    parc_tvs_shen[i,:] = tvs_parc_shen \n",
    "    \n",
    "    subjects_loaded.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc985c9-9647-495a-abb9-ee2fade0efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_loaded_s = subjects #pd.Series(subjects_loaded, name='Subject', dtype=str)\n",
    "\n",
    "threat_shen = pd.concat([pd.Series(subjects_loaded_s, name='Subject', dtype = str),pd.DataFrame(parc_threat_shen, dtype=float)], axis=1).set_index('Subject')\n",
    "safety_shen = pd.concat([pd.Series(subjects_loaded_s, name='Subject', dtype = str),pd.DataFrame(parc_safety_shen, dtype=float)], axis=1).set_index('Subject')\n",
    "tvs_shen = pd.concat([pd.Series(subjects_loaded_s, name='Subject', dtype = str),pd.DataFrame(parc_tvs_shen, dtype=float)], axis=1).set_index('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20353f3c-c021-469e-885e-aeb405e7d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_shen.to_csv(analysis + '/ThreatVsBaseline_Shen368_Data_n={}_{}.csv'.format(len(threat_shen), unique_id))\n",
    "safety_shen.to_csv(analysis + '/SafetyVsBaseline_Shen368_Data_n={}_{}.csv'.format(len(safety_shen), unique_id))\n",
    "tvs_shen.to_csv(analysis + '/ThreatVsSafety_Shen368_Data_n={}_{}.csv'.format(len(threat_shen), unique_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46043129-0831-4cc7-9bff-00bde27325fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis + '/ThreatVsBaseline_Shen368_Data_n={}_{}.csv'.format(len(threat_shen), unique_id))\n",
    "print(analysis + '/SafetyVsBaseline_Shen368_Data_n={}_{}.csv'.format(len(safety_shen), unique_id))\n",
    "print(analysis + '/ThreatVsSafety_Shen368_Data_n={}_{}.csv'.format(len(threat_shen), unique_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c331df2-2ec0-4e4c-aaba-0b6c3eec16b4",
   "metadata": {},
   "source": [
    "### Read in already-parcellated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f3c7f-5120-47a4-8b86-2572310b0ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in de-meaned data\n",
    "# parc_date = '2024-02-27'\n",
    "# threat_vmpfc = pd.read_csv(analysis + '/ThreatVsBaseline_Subcortical_Mackey_Data_demeaned_n=124_{}.csv'.format(parc_date), index_col = 0).set_index('Subject')\n",
    "# safety_vmpfc = pd.read_csv(analysis + '/SafetyVsBaseline_Subcortical_Mackey_Data_demeaned_n=124_{}.csv'.format(parc_date), index_col = 0).set_index('Subject')\n",
    "# tvs_vmpfc = pd.read_csv(analysis + '/ThreatVsSafety_Subcortical_Mackey_Data_demeaned_n=124_{}.csv'.format(parc_date), index_col = 0).set_index('Subject')\n",
    "\n",
    "# parc_date_shen = '2024-02-27'\n",
    "# threat_shen = pd.read_csv(analysis + '/ThreatVsBaseline_Shen368_Data_demeaned_n=124_{}.csv'.format(parc_date_shen), index_col = 0)\n",
    "# safety_shen = pd.read_csv(analysis + '/SafetyVsBaseline_Shen368_Data_demeaned_n=124_{}.csv'.format(parc_date_shen), index_col = 0)\n",
    "# tvs_shen = pd.read_csv(analysis + '/ThreatVsSafety_Shen368_Data_demeaned_n=124_{}.csv'.format(parc_date_shen), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e2e5e-0991-4365-ad26-126608999957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in non-demeaned data\n",
    "parc_date = '2024-06-21'\n",
    "# ThreatVsBaseline_Subcortical_Mackey_Data_n=124_2024-03-21_NotDemeaned.csv'\n",
    "threat_vmpfc = pd.read_csv(analysis + '/ThreatVsBaseline_Subcortical_Mackey_vmPFC_CopeData_n=132_{}_NotDemeaned.csv'.format(parc_date), index_col = 0).set_index('Subject').drop('sub-A647', axis=0).reset_index()\n",
    "safety_vmpfc = pd.read_csv(analysis + '/SafetyVsBaseline_Subcortical_Mackey_vmPFC_CopeData_n=132_{}_NotDemeaned.csv'.format(parc_date), index_col = 0).set_index('Subject').drop('sub-A647', axis=0).reset_index()\n",
    "tvs_vmpfc = pd.read_csv(analysis + '/ThreatVsSafety_Subcortical_Mackey_vmPFC_CopeData_n=132_{}_NotDemeaned.csv'.format(parc_date), index_col = 0).set_index('Subject').drop('sub-A647', axis=0).reset_index()\n",
    "\n",
    "# # Shen data\n",
    "# parc_date_shen = '2024-04-15'\n",
    "# threat_shen = pd.read_csv(analysis + '/ThreatVsBaseline_Shen368_CopeData_n=124_NotDemeaned.csv'.format(parc_date_shen), index_col = 0)\n",
    "# safety_shen = pd.read_csv(analysis + '/SafetyVsBaseline_Shen368_CopeData_n=124_NotDemeaned.csv'.format(parc_date_shen), index_col = 0)\n",
    "# tvs_shen = pd.read_csv(analysis + '/ThreatVsSafety_Shen368_CopeData_n=124_NotDemeaned.csv'.format(parc_date_shen), index_col = 0)\n",
    "\n",
    "# # Harvard/Oxford dACC data\n",
    "# parc_date_dacc = '2024-06-20'\n",
    "# threat_dacc = pd.read_csv(analysis + '/ThreatVsBaseline_Subcortical_AAL3_dACC_CopeData_n=124_{}_NotDemeaned.csv'.format(parc_date_dacc), index_col = 0)\n",
    "# safety_dacc = pd.read_csv(analysis + '/SafetyVsBaseline_Subcortical_AAL3_dACC_CopeData_n=124_{}_NotDemeaned.csv'.format(parc_date_dacc), index_col = 0)\n",
    "# tvs_dacc = pd.read_csv(analysis + '/ThreatVsSafety_Subcortical_AAL3_dACC_CopeData_n=124_{}_NotDemeaned.csv'.format(parc_date_dacc), index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-motel",
   "metadata": {},
   "source": [
    "### Regress covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82b721-b289-4ec7-ae97-a360c395348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_data = threat_shen\n",
    "safety_data = safety_shen\n",
    "tvs_data = tvs_shen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to regress covariates\n",
    "\n",
    "def regress_covariates(x_data_in, y_data_in, mean_activation, regress_mean):\n",
    "    \n",
    "    # Define matrix for regressed data\n",
    "    regressed_data = np.ones(y_data_in.shape)\n",
    "\n",
    "    if regress_mean == True:\n",
    "        x_data_in = pd.concat([x_data_in, mean_activation], axis=1)\n",
    "        print(len(x_data_in), len(mean_activation))\n",
    "        assert len(x_data_in) == len(mean_activation)\n",
    "    else:\n",
    "        print(\"Not regressing mean activation\")\n",
    "\n",
    "    # Regress covariates column-wise\n",
    "    for i in range(0, y_data_in.shape[1]):\n",
    "        if i == .25*y_data_in.shape[1]:\n",
    "            print(\"1/4 way through!\")\n",
    "        elif i == .5*y_data_in.shape[1]:\n",
    "            print(\"1/2 way through!\")\n",
    "        elif i == .75*y_data_in.shape[1]:\n",
    "            print(\"3/4 way through!\")\n",
    "        y_col = y_data_in.iloc[:,i]\n",
    "        model = OLS(y_col, x_data_in)\n",
    "        results = model.fit()\n",
    "        print(results.summary())\n",
    "        regressed_data[:, i] = results.resid\n",
    "    \n",
    "    # Put residuals in a data frame\n",
    "    reg_df = pd.DataFrame(regressed_data, columns = y_data_in.columns)\n",
    "    \n",
    "    return reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do covariate regression\n",
    "x_df = pd.merge(threat_data.reset_index()['Subject'], bv_df_orig[['Subject', 'eTIV', 'site_bin', 'mean_fd', 'age_at_scan']]) #Merge to ensure same subject order\n",
    "\n",
    "x_data = deepcopy(x_df).set_index('Subject')\n",
    "x_data['eTIV'] = zscore(x_data['eTIV'])\n",
    "x_data['mean_fd'] = zscore(x_data['mean_fd'])\n",
    "x_data['age_at_scan'] = zscore(x_data['age_at_scan'])\n",
    "x_data = sm.add_constant(x_data) #Add intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a985a-5191-4d21-8711-8c9eb6529f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variance inflation factor (code from https://stackoverflow.com/questions/42658379/variance-inflation-factor-in-python)\n",
    "vifs = pd.DataFrame(np.linalg.inv(x_data.drop(\"const\", axis=1).corr().to_numpy()).diagonal(), \n",
    "                 index=x_data.columns.drop(\"const\"), \n",
    "                 columns=['VIF'])\n",
    "# vifs\n",
    "drop_vifs = np.where(vifs['VIF']>5)[0].tolist()\n",
    "\n",
    "vifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfccce7-2915-42f6-8757-58ab25a68696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random spot checks to ensure subjects in same order\n",
    "# # ROI data\n",
    "# assert x_df['Subject'].iloc[-1] == threat_data.index.iloc[-1]\n",
    "# assert x_df['Subject'].iloc[-1] == tvs_data['Subject'].iloc[-1]\n",
    "# assert x_df['Subject'].iloc[-1] == safety_data['Subject'].iloc[-1]\n",
    "\n",
    "# assert x_df['Subject'].iloc[23] == threat_data['Subject'].iloc[23]\n",
    "# assert x_df['Subject'].iloc[23] == tvs_data['Subject'].iloc[23]\n",
    "# assert x_df['Subject'].iloc[23] == safety_data['Subject'].iloc[23]\n",
    "\n",
    "# assert x_df['Subject'].iloc[78] == threat_data['Subject'].iloc[78]\n",
    "# assert x_df['Subject'].iloc[78] == tvs_data['Subject'].iloc[78]\n",
    "# assert x_df['Subject'].iloc[78] == safety_data['Subject'].iloc[78]\n",
    "\n",
    "# Shen data\n",
    "assert x_df['Subject'].iloc[-1] == threat_shen.index[-1]\n",
    "assert x_df['Subject'].iloc[-1] == tvs_shen.index[-1]\n",
    "assert x_df['Subject'].iloc[-1] == safety_shen.index[-1]\n",
    "\n",
    "assert x_df['Subject'].iloc[23] == threat_shen.index[23]\n",
    "assert x_df['Subject'].iloc[23] == tvs_shen.index[23]\n",
    "assert x_df['Subject'].iloc[23] == safety_shen.index[23]\n",
    "\n",
    "assert x_df['Subject'].iloc[78] == threat_shen.index[78]\n",
    "assert x_df['Subject'].iloc[78] == tvs_shen.index[78]\n",
    "assert x_df['Subject'].iloc[78] == safety_shen.index[78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4a8ed-848f-4ac8-b560-4947a1745297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Regress covariates from means (reset indices to avoid mis-matched index error (subs vs numbers))\n",
    "# threat_shen_mean_reg = regress_covariates(x_data, threat_means.reset_index(drop=True), regress_mean=True)#.drop(['Subject'], axis=1)).set_index(threat_means['Subject'])\n",
    "# safety_shen_mean_reg = regress_covariates(x_data, safety_means.reset_index(drop=True), regress_mean=True)#.drop(['Subject'], axis=1)).set_index(threat_means['Subject'])\n",
    "# tvs_shen_mean_reg = regress_covariates(x_data, tvs_means.reset_index(drop=True), regress_mean=True)#.drop(['Subject'], axis=1)).set_index(threat_means['Subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f2140-b7b3-474d-b74e-b9c3e479bda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do covariate regressions--Mackey + Subcort data\n",
    "threat_reg_mackey = regress_covariates(x_data, threat_data.set_index('Subject'), threat_means.set_index('Subject'), regress_mean=True)\n",
    "safety_reg_mackey = regress_covariates(x_data, safety_data.set_index('Subject'), safety_means.set_index('Subject'), regress_mean=True)\n",
    "tvs_reg_mackey = regress_covariates(x_data, tvs_data.set_index('Subject'), tvs_means.set_index('Subject'), regress_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343a66b-6446-4190-9e32-fe650fd5fa85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do covariate regressions--Shen data\n",
    "threat_reg_shen = regress_covariates(x_data, threat_shen, threat_means.set_index('Subject'), regress_mean=True)\n",
    "safety_reg_shen = regress_covariates(x_data, safety_shen, safety_means.set_index('Subject'), regress_mean=True)\n",
    "tvs_reg_shen = regress_covariates(x_data, tvs_shen, tvs_means.set_index('Subject'), regress_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64159113-a0ed-484d-be39-32275a7c4b80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do covariate regressions--dACC data\n",
    "threat_reg_dacc = regress_covariates(x_data, threat_data.set_index('Subject'), threat_means.set_index('Subject'), regress_mean=True)\n",
    "safety_reg_dacc = regress_covariates(x_data, safety_data.set_index('Subject'), safety_means.set_index('Subject'), regress_mean=True)\n",
    "tvs_reg_dacc = regress_covariates(x_data, tvs_data.set_index('Subject'), tvs_means.set_index('Subject'), regress_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c462d44a-e758-412f-ac64-9a568c4f9be6",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c778a3-5c00-4024-b410-a635c8c8b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write regressed means to csv (covariates regressed from single mean activation column)\n",
    "# threat_shen_mean_reg.to_csv(analysis + '/ThreatVsBaseline_MeanActivation_regressed_n={}_{}.csv'.format(len(threat_shen_mean_reg), today))\n",
    "# safety_shen_mean_reg.to_csv(analysis + '/SafetyVsBaseline_MeanActivation_regressed_n={}_{}.csv'.format(len(safety_shen_mean_reg), today))\n",
    "# tvs_shen_mean_reg.to_csv(analysis + '/ThreatVsSafety_MeanActivation_regressed_n={}_{}.csv'.format(len(tvs_shen_mean_reg), today))\n",
    "\n",
    "# print(analysis + '/ThreatVsBaseline_MeanActivation_regressed_n={}_{}.csv'.format(len(threat_vmpfc), today))\n",
    "# print(analysis + '/SafetyVsBaseline_MeanActivation_regressed_n={}_{}.csv'.format(len(safety_vmpfc), today))\n",
    "# print(analysis + '/ThreatVsSafety_MeanActivation_regressed_n={}_{}.csv'.format(len(threat_vmpfc), today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output Shen data (covariates regressed from demeaned data)\n",
    "today = str(date.today())\n",
    "\n",
    "threat_reg_shen_df = pd.concat([x_df['Subject'], threat_reg_shen], axis=1).set_index('Subject')\n",
    "threat_outfile = analysis + '/Regressed_ThreatVBaseline_Shen368_FSL_CopeBetas_n={}_{}.csv'.format(len(threat_reg_shen_df), unique_id)\n",
    "threat_reg_shen_df.to_csv(threat_outfile)\n",
    "print(threat_outfile)\n",
    "\n",
    "safety_reg_shen_df = pd.concat([x_df['Subject'], safety_reg_shen], axis=1).set_index('Subject')\n",
    "safety_outfile = analysis + '/Regressed_SafetyVBaseline_Shen368_FSL_CopeBetas_n={}_{}.csv'.format(len(safety_reg_shen_df), unique_id)\n",
    "safety_reg_shen_df.to_csv(safety_outfile)\n",
    "print(safety_outfile)\n",
    "\n",
    "tvs_reg_shen_df = pd.concat([x_df['Subject'], tvs_reg_shen], axis=1).set_index('Subject')\n",
    "tvs_outfile = analysis + '/Regressed_ThreatVSafety_Shen368_FSL_CopeBetas_n={}_{}.csv'.format(len(tvs_reg_shen_df), unique_id)\n",
    "tvs_reg_shen_df.to_csv(tvs_outfile)\n",
    "print(tvs_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15935e1a-dc76-43d8-94f2-98788d9dcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MACKEY & SUBCORT DATA (covariates regressed from demeaned data)\n",
    "# Save output\n",
    "today = str(date.today())\n",
    "\n",
    "threat_reg_mackey_df = pd.concat([x_df['Subject'], threat_reg_mackey], axis=1).set_index('Subject')\n",
    "threat_outfile = analysis + '/Regressed_ThreatVBaseline_Mackey_FSL_CopeBetas_n={}_{}.csv'.format(len(threat_reg_mackey), unique_id)\n",
    "threat_reg_mackey_df.to_csv(threat_outfile)\n",
    "print(threat_outfile)\n",
    "\n",
    "safety_reg_mackey_df = pd.concat([x_df['Subject'], safety_reg_mackey], axis=1).set_index('Subject')\n",
    "safety_outfile = analysis + '/Regressed_SafetyVBaseline_Mackey_FSL_CopeBetas_n={}_{}.csv'.format(len(safety_reg_mackey), unique_id)\n",
    "safety_reg_mackey_df.to_csv(safety_outfile)\n",
    "print(safety_outfile)\n",
    "\n",
    "tvs_reg_mackey_df = pd.concat([x_df['Subject'], tvs_reg_mackey], axis=1).set_index('Subject')\n",
    "tvs_outfile = analysis + '/Regressed_ThreatVSafety_Mackey_FSL_CopeBetas_n={}_{}.csv'.format(len(tvs_reg_mackey), unique_id)\n",
    "tvs_reg_mackey_df.to_csv(tvs_outfile)\n",
    "print(tvs_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1e62a-dbc8-48e7-b470-668ce631b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dACC DATA (covariates regressed from demeaned data)\n",
    "# Save output\n",
    "today = str(date.today())\n",
    "\n",
    "if roi_dict == aal_dacc_dict:\n",
    "    threat_reg_dacc_df = pd.concat([x_df['Subject'], threat_reg_dacc], axis=1).set_index('Subject')\n",
    "    threat_outfile = analysis + '/Regressed_ThreatVBaseline_AAL3_dACC_FSL_CopeBetas_n={}_{}.csv'.format(len(threat_reg_dacc), unique_id)\n",
    "    threat_reg_dacc_df.to_csv(threat_outfile)\n",
    "    print(threat_outfile)\n",
    "    \n",
    "    safety_reg_dacc_df = pd.concat([x_df['Subject'], safety_reg_dacc], axis=1).set_index('Subject')\n",
    "    safety_outfile = analysis + '/Regressed_SafetyVBaseline_AAL3_dACC_FSL_CopeBetas_n={}_{}.csv'.format(len(safety_reg_dacc), unique_id)\n",
    "    safety_reg_dacc_df.to_csv(safety_outfile)\n",
    "    print(safety_outfile)\n",
    "    \n",
    "    tvs_reg_dacc_df = pd.concat([x_df['Subject'], tvs_reg_dacc], axis=1).set_index('Subject')\n",
    "    tvs_outfile = analysis + '/Regressed_ThreatVSafety_AAL3_dACC_FSL_CopeBetas_n={}_{}.csv'.format(len(tvs_reg_dacc), unique_id)\n",
    "    tvs_reg_dacc_df.to_csv(tvs_outfile)\n",
    "    print(tvs_outfile)\n",
    "elif roi_dict == ho_dacc_dict:\n",
    "    threat_reg_dacc_df = pd.concat([x_df['Subject'], threat_reg_dacc], axis=1).set_index('Subject')\n",
    "    threat_outfile = analysis + '/Regressed_ThreatVBaseline_HarvardOxford_dACC_FSL_CopeBetas_n={}_{}.csv'.format(len(threat_reg_dacc), unique_id)\n",
    "    threat_reg_dacc_df.to_csv(threat_outfile)\n",
    "    print(threat_outfile)\n",
    "    \n",
    "    safety_reg_dacc_df = pd.concat([x_df['Subject'], safety_reg_dacc], axis=1).set_index('Subject')\n",
    "    safety_outfile = analysis + '/Regressed_SafetyVBaseline_HarvardOxford_dACC_FSL_CopeBetas_n={}_{}.csv'.format(len(safety_reg_dacc), unique_id)\n",
    "    safety_reg_dacc_df.to_csv(safety_outfile)\n",
    "    print(safety_outfile)\n",
    "    \n",
    "    tvs_reg_dacc_df = pd.concat([x_df['Subject'], tvs_reg_dacc], axis=1).set_index('Subject')\n",
    "    tvs_outfile = analysis + '/Regressed_ThreatVSafety_HarvardOxford_dACC_FSL_CopeBetas_n={}_{}.csv'.format(len(tvs_reg_dacc), unique_id)\n",
    "    tvs_reg_dacc_df.to_csv(tvs_outfile)\n",
    "    print(tvs_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280107ef-9b5a-41ad-b9b8-92427834c7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
