{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from netneurotools import cluster \n",
    "# from netneurotools import plotting as nnt_plotting\n",
    "import nibabel as nib\n",
    "from stepmix.stepmix import StepMix\n",
    "from stepmix.bootstrap import blrt\n",
    "from nilearn.maskers import NiftiMasker, NiftiLabelsMasker\n",
    "from nilearn import plotting, datasets, image\n",
    "from sklearn.linear_model import RidgeClassifier, ElasticNet, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from statistics import mode\n",
    "from scipy.stats import kruskal, pearsonr, spearmanr, mannwhitneyu, zscore, median_abs_deviation, iqr\n",
    "from statsmodels.stats.multitest import fdrcorrection as fdr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "import statannotations as sa\n",
    "from statannotations.Annotator import Annotator\n",
    "import statsmodels.formula.api as smf\n",
    "from pingouin import pairwise_gameshowell, mwu, pairwise_tests, ttest\n",
    "from datetime import date\n",
    "from re import match\n",
    "import starbars\n",
    "from IPython.display import display\n",
    "\n",
    "today=str(date.today())\n",
    "\n",
    "sns.set_palette('Paired')\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d1151-d18f-42ec-aa16-01d135c63d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "sns.set_style(sns.set_style('whitegrid', {'font.family':'serif', 'font.serif':'Times New Roman'}))\n",
    "sns.set_palette('nipy_spectral_r', n_colors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and variables\n",
    "home = '/gpfs/milgram/pi/gee_dylan/candlab/data'\n",
    "hcpdata = home + '/mri/hcp_pipeline_preproc/shapes'\n",
    "taskfiles = home + '/behavioral/shapes/task_design_trialwise'\n",
    "datapath = '/gpfs/milgram/pi/gee_dylan/candlab/analyses/shapes/shapes_phenotyping'\n",
    "fslpath = '/home/tjk33/project/SHAPES_task_act/out'\n",
    "analysis = datapath + '/Analysis'\n",
    "suffix = 'bold_8dv_resampled.nii.gz'\n",
    "plt_out = analysis + '/Figures'\n",
    "\n",
    "bv_df_orig = pd.read_csv(analysis + '/Behav_Dataset_AdulthoodRegr_n=131_2024-06-21.csv') #3-08 version includes updated dev stage vars\n",
    "subjects = bv_df_orig['Subject'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to categorical and standardize in behav df\n",
    "bv_df_orig['sex'] = bv_df_orig['sex'].astype('category')\n",
    "bv_df_orig['years_education'] = bv_df_orig['years_education'].astype('category')\n",
    "bv_df_orig['combined_income'] = bv_df_orig['combined_income'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in betas\n",
    "betas_date_mackey = '2024-06-21' #'2023-12-21'#\n",
    "betas_date_shen = '2024-06-27'\n",
    "betas_date_dacc = '2024-06-21' #'2024-06-18'\n",
    "dacc_roi = 'AAL3'\n",
    "#Need to drop cerebellar nodes? Think they are 341-368\n",
    "\n",
    "## Shen Data\n",
    "threat_reg_df_shen = pd.read_csv(analysis + '/Regressed_ThreatVBaseline_Shen368_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(betas_date_shen)).set_index('Subject')\n",
    "safety_reg_df_shen = pd.read_csv(analysis + '/Regressed_SafetyVBaseline_Shen368_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(betas_date_shen)).set_index('Subject')\n",
    "tvs_reg_df_shen = pd.read_csv(analysis + '/Regressed_ThreatVSafety_Shen368_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(betas_date_shen)).set_index('Subject')\n",
    "\n",
    "# Mackey & Subcort data\n",
    "threat_reg_df = pd.read_csv(analysis + '/Regressed_ThreatVBaseline_Mackey_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(betas_date_mackey)).set_index('Subject')\n",
    "safety_reg_df = pd.read_csv(analysis + '/Regressed_SafetyVBaseline_Mackey_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(betas_date_mackey)).set_index('Subject')\n",
    "tvs_reg_df = pd.read_csv(analysis + '/Regressed_ThreatVSafety_Mackey_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(betas_date_mackey)).set_index('Subject')\n",
    "\n",
    "# dACC data\n",
    "threat_reg_dacc = pd.read_csv(analysis + '/Regressed_ThreatVBaseline_{}_dACC_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(dacc_roi, betas_date_dacc)).set_index('Subject').rename(columns = {'{}_dACC'.format(dacc_roi):'{}_dACC_thr'.format(dacc_roi)})\n",
    "safety_reg_dacc = pd.read_csv(analysis + '/Regressed_SafetyVBaseline_{}_dACC_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(dacc_roi, betas_date_dacc)).set_index('Subject').rename(columns = {'{}_dACC'.format(dacc_roi):'{}_dACC_saf'.format(dacc_roi)})\n",
    "tvs_reg_dacc = pd.read_csv(analysis + '/Regressed_ThreatVSafety_{}_dACC_FSL_CopeBetas_n=131_{}_NotDemeaned.csv'.format(dacc_roi, betas_date_dacc)).set_index('Subject').rename(columns = {'{}_dACC'.format(dacc_roi):'{}_dACC_tvs'.format(dacc_roi)})\n",
    "sublist = safety_reg_dacc.reset_index()['Subject'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbb2dc-ba53-4315-bdc3-ac84e3c4e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge subcort and dACC dat\n",
    "threat_reg_sd = pd.merge(threat_reg_df.reset_index(), threat_reg_dacc.reset_index(), on='Subject')\n",
    "safety_reg_sd =pd.merge(safety_reg_df.reset_index(), safety_reg_dacc.reset_index(), on='Subject')\n",
    "tvs_reg_sd = pd.merge(tvs_reg_df.reset_index(), tvs_reg_dacc.reset_index(), on='Subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-elimination",
   "metadata": {},
   "source": [
    "### Get Dataset Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_m = len(bv_df_orig[bv_df_orig['sex'] == 0])\n",
    "n_f = len(bv_df_orig[bv_df_orig['sex'] == 1])\n",
    "n_tot = len(bv_df_orig)\n",
    "\n",
    "print(\"Participant sample is {}% male and {}% female\".format(round(n_m/n_tot*100, 3), round(n_f/n_tot*100, 3)))\n",
    "print(\"Mean age is {}, std {}\".format(round(bv_df_orig['age_at_ri'].mean(), 3), round(bv_df_orig['age_at_ri'].std(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "bv_df_merged = pd.merge(tvs_reg_df.reset_index()['Subject'], bv_df_orig).reset_index()\n",
    "bv_df_merged['anx_dep_sx'] = np.sqrt(bv_df_merged['Anxiety_Problems_Total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-treasurer",
   "metadata": {},
   "source": [
    "### Collapse across left and right hemispheres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_hemispheres(df, cond):\n",
    "    collapsed_df = pd.DataFrame(df['Subject'])\n",
    "    collapsed_df['hipp_{}'.format(cond)] = np.mean((df['left_hippocampus_Shen368'], df['right_hippocampus_Shen368']), axis=0)\n",
    "    collapsed_df['amyg_{}'.format(cond)] = np.mean((df['left_amygdala_Shen368'], df['right_amygdala_Shen368']), axis=0)\n",
    "    collapsed_df['{}_dACC_{}'.format(dacc_roi, cond)] = df['{}_dACC_{}'.format(dacc_roi, cond)]\n",
    "    collapsed_df['Mackey_14m_{}'.format(cond)] = np.mean((df['Mackey_area14m_left'], df['Mackey_area14m_right']), axis=0)\n",
    "    # collapsed_df['Mackey_14rr_{}'.format(cond)] = np.mean((df['Mackey_area14rr_left'], df['Mackey_area14rr_right']), axis=0)\n",
    "    # collapsed_df['Mackey_14r_{}'.format(cond)] = np.mean((df['Mackey_area14r_left'], df['Mackey_area14r_right']), axis=0)\n",
    "    collapsed_df['Mackey_32_{}'.format(cond)] = np.mean((df['Mackey_area32_left'], df['Mackey_area32_right']), axis=0)\n",
    "    collapsed_df['Mackey_25_{}'.format(cond)] = np.mean((df['Mackey_area25_left'], df['Mackey_area25_right']), axis=0)\n",
    "    # collapsed_df['Mackey_14c_{}'.format(cond)] = np.mean((df['Mackey_area14c_left'], df['Mackey_area14c_right']), axis=0)\n",
    "    collapsed_df['Mackey_24_{}'.format(cond)] = np.mean((df['Mackey_area24_left'], df['Mackey_area24_right']), axis=0)\n",
    "    # collapsed_df['Mackey_11m_{}'.format(cond)] = np.mean((df['Mackey_area11m_left'], df['Mackey_area11m_right']), axis=0)\n",
    "    return collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ea038-4e6c-485e-848b-9638839c6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse across hemispheres\n",
    "safety_coll_df = collapse_hemispheres(safety_reg_sd.reset_index(), 'saf')\n",
    "threat_coll_df = collapse_hemispheres(threat_reg_sd.reset_index(), 'thr')\n",
    "tvs_coll_df = collapse_hemispheres(tvs_reg_sd.reset_index(), 'tvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b89bd-8001-4b75-a86f-1836d039d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute averaged node for regions that are highly correlated\n",
    "safety_coll_df['Mackey_32_14m_saf'] = (safety_coll_df['Mackey_32_saf'] + safety_coll_df['Mackey_14m_saf'])/2\n",
    "safety_coll_df = safety_coll_df.drop(['Mackey_32_saf', 'Mackey_14m_saf'], axis=1)\n",
    "\n",
    "threat_coll_df['Mackey_32_14m_thr'] = (threat_coll_df['Mackey_32_thr'] +  threat_coll_df['Mackey_14m_thr'])/2\n",
    "threat_coll_df = threat_coll_df.drop(['Mackey_14m_thr','Mackey_32_thr'], axis=1 )\n",
    "\n",
    "tvs_coll_df['Mackey_32_14m_tvs'] = (tvs_coll_df['Mackey_32_tvs'] + tvs_coll_df['Mackey_14m_tvs'])/2\n",
    "tvs_coll_df = tvs_coll_df.drop(['Mackey_32_tvs', 'Mackey_14m_tvs'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9aa8e-944a-457a-8f86-a1c3fae838c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate threat and safety measures into one data frame\n",
    "all_coll_df = zscore(pd.concat([threat_coll_df.set_index('Subject'), safety_coll_df.set_index('Subject')],\n",
    "                        axis=1).dropna(), axis=0) #Z-score other conditions\n",
    "\n",
    "adv_binned_df = pd.concat([bv_df_merged.set_index('Subject')[['Early_Childhood_regr', 'Mid_Childhood_regr', 'Adolescence_regr', 'Adulthood_regr']],\n",
    "                            all_coll_df], axis=1)\n",
    "\n",
    "adv_binned_tvs = pd.concat([bv_df_merged.set_index('Subject')[['Early_Childhood_regr', 'Mid_Childhood_regr', 'Adolescence_regr', 'Adulthood_regr']],\n",
    "                            tvs_coll_df.set_index('Subject')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-construction",
   "metadata": {},
   "source": [
    "### Set input data for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0f66e-f9c4-4021-98f0-c16dc3c65764",
   "metadata": {},
   "source": [
    "NOTE: Large fronto-orbital brightness artifact in many scans makes analyzing this region challenging (Paola mentioned this to me and can also be observed in preprocessed data images). For this reason, we should exclude Mackey parcellations 14rr, 11m, 14c, 14r. Parcellations 24, 25, 32, and 14m are okay to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for outliers (based on median for adversity)\n",
    "\n",
    "def get_outliers(df, var):\n",
    "    #Define median and standard deviation\n",
    "    vmn = df[var].median()\n",
    "    vstd = df[var].std()\n",
    "    # Outliers are greater or less than 3x standard dev from median\n",
    "    outliers = np.where((df[var] > vmn + (3*vstd)) | (df[var] < vmn - (3*vstd)))\n",
    "    \n",
    "    return pd.Series(outliers[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input data HERE\n",
    "data_prep = adv_binned_tvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6b08f-062d-4245-a9fe-73e966ead05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "\n",
    "for i in range(0, len(data_prep.columns)):\n",
    "    col = data_prep.columns[i]\n",
    "    outs = get_outliers(data_prep, col)\n",
    "    for j in range(0, len(outs)):\n",
    "        outliers.append(outs[j])\n",
    "        \n",
    "all_outliers = list(set(outliers))\n",
    "print('Dropping {} subjects with outlier data; new sample is {} pts'.format(len(all_outliers), len(data_prep.reset_index().drop(all_outliers, axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2823f3c-60a9-4c5c-9a0f-64dd82e0180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers and set up input data\n",
    "in_beta_mat_pre = data_prep.reset_index().drop(all_outliers, axis=0).set_index('Subject')\n",
    "\n",
    "# Set input data and standardize\n",
    "in_beta_mat = zscore(in_beta_mat_pre, axis=0)\n",
    "\n",
    "# Drop outliers from behavioral data\n",
    "bv_df = bv_df_merged.reset_index().drop(all_outliers, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a79f74-9b29-4639-9792-e8c29d26c646",
   "metadata": {},
   "source": [
    "### Set up analysis df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variance inflation factor (code from https://stackoverflow.com/questions/42658379/variance-inflation-factor-in-python)\n",
    "vifs = pd.DataFrame(np.linalg.inv(in_beta_mat.corr().to_numpy()).diagonal(), \n",
    "                 index=in_beta_mat.columns, \n",
    "                 columns=['VIF'])\n",
    "# vifs\n",
    "drop_vifs = np.where(vifs['VIF']>5)[0].tolist()\n",
    "\n",
    "vifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "corr_df = pd.merge(in_beta_mat.reset_index(), bv_df_orig.loc[:, [\"Subject\", \"Anxiety_Problems_Total\", 'Internalizing_Problems_Total', 'CTQ_Total',\n",
    "                                                                'Early_Childhood', 'Mid_Childhood', 'Adolescence', 'Adulthood', 'Total_Events']],\n",
    "                  on='Subject', suffixes=(None, '_merged')).set_index('Subject').dropna(axis=0)\n",
    "corr = in_beta_mat.corr()\n",
    "print(corr.shape)\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10,10))\n",
    "\n",
    "\n",
    "sns.heatmap(corr, cmap='coolwarm', vmin=-1, vmax=1,  ax=ax, annot=True, annot_kws={\"size\":\"xx-small\"})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-addition",
   "metadata": {},
   "source": [
    "### LPA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e74c4-4c35-44cd-911c-69e3161e8d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from stepmix.stepmix import StepMix\n",
    "info_crits = dict(n_comps = [], BIC=[], AIC=[], CAIC = [], Avg_LL=[], SS_BIC = [], Entropy=[], Scaled_Entropy = [])\n",
    "\n",
    "# Gaussian mixture model\n",
    "for i in range(1, 7):\n",
    "    model = StepMix(n_components=i, measurement=\"continuous\", init_params = 'random',\n",
    "                    verbose=1, random_state=0, n_init=1000)\n",
    "    \n",
    "    # Fit to data\n",
    "    model.fit(in_beta_mat)\n",
    "    bic = model.bic(in_beta_mat)\n",
    "    aic = model.aic(in_beta_mat)\n",
    "    caic = model.caic(in_beta_mat)\n",
    "    log_lik = model.score(in_beta_mat)\n",
    "    ss_bic = model.sabic(in_beta_mat)\n",
    "    entropy = model.entropy(in_beta_mat)\n",
    "    scaled_entropy = model.relative_entropy(in_beta_mat)\n",
    "    \n",
    "    info_crits['n_comps'].append(i)\n",
    "    info_crits['BIC'].append(bic)\n",
    "    info_crits['AIC'].append(aic)\n",
    "    info_crits['CAIC'].append(caic)\n",
    "    info_crits['Avg_LL'].append(log_lik)\n",
    "    info_crits['SS_BIC'].append(ss_bic)\n",
    "    info_crits['Entropy'].append(entropy)\n",
    "    info_crits['Scaled_Entropy'].append(scaled_entropy)\n",
    "\n",
    "    # Save class membership predictions to df\n",
    "    # model.predict(in_beta_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5373341-9eef-48c7-b969-0e056baca9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at BIC estimations\n",
    "bic_df = pd.DataFrame(info_crits).round(4)\n",
    "\n",
    "printmd('**Information criteria for hemispheres averaged together**')\n",
    "bic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fafd8c-936a-412a-b326-f1a0c3c78784",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = StepMix(n_components = 3, measurement=\"continuous\", init_params = 'random',\n",
    "                      verbose=1, random_state=0, n_init=1000, \n",
    "                      n_steps = 3, correction='BCH', assignment='soft')\n",
    "final_model.fit(in_beta_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586d141-8309-4253-a6bc-2f669dcd60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.score(in_beta_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c7228-bc6a-42a3-b6cc-3662e559f8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "k_less1 = 3\n",
    "\n",
    "# Bootstrapped likelihood ratio test\n",
    "null_model_2 = StepMix(n_components=k_less1, measurement=\"continuous\", init_params = 'random',\n",
    "                      verbose=1, random_state=0, n_init=1000, \n",
    "                      correction='BCH', assignment='soft')\n",
    "\n",
    "# Bootstrapped likelihood ratio test\n",
    "final_model = StepMix(n_components=k, measurement=\"continuous\", init_params = 'random',\n",
    "                      verbose=1, random_state=0, n_init=1000, \n",
    "                      correction='BCH', assignment='soft')\n",
    "\n",
    "blt1 = blrt(null_model_2, final_model, X = in_beta_mat, n_repetitions=1000)\n",
    "print(\"2 classes vs. 3 classes: p={}\".format(blt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52120b76-0ffd-4522-a5b2-b2151f53b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} classes vs. {} classes: p={}\".format(k, k_less1, blt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1caed-5edb-4b91-a316-8419d70f9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LPA clusters\n",
    "lpa_clusters = final_model.predict(in_beta_mat)\n",
    "cluster_prob = final_model.predict_proba(in_beta_mat)\n",
    "cluster_prob_df = pd.DataFrame(cluster_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgimm_cluster_df = pd.DataFrame(in_beta_mat.reset_index()[['Subject']].dropna(axis=0)) \n",
    "bgimm_cluster_df['ClusterID'] = lpa_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bgimm_cluster_df.groupby('ClusterID').count().iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163a904-ddc0-4d26-bf65-7f6c6df0e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_hems_clustrs = bgimm_cluster_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68cdbc-b38b-4e5a-9fad-2ca108570867",
   "metadata": {},
   "outputs": [],
   "source": [
    "summdf = pd.merge(both_hems_clustrs, bv_df)\n",
    "print(summdf[['ClusterID', 'Total_Events']].groupby('ClusterID').median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-flood",
   "metadata": {},
   "source": [
    "### Evaluate Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which data to merge in\n",
    "m1 = pd.merge(bgimm_cluster_df, in_beta_mat.reset_index(), how = 'inner')\n",
    "m2 = pd.merge(m1, bv_df_orig, how = 'left', on='Subject', suffixes=(None, '_bvdf'))\n",
    "\n",
    "#Drop participants without RI data\n",
    "group_df_orig = m2#.dropna(axis=0, subset=['Total_Events'])\n",
    "group_df_orig['ClusterID'] = group_df_orig['ClusterID'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Cluster ID with whole-brain results map\n",
    "clust_beta_df = group_df_orig[['Subject', 'ClusterID']]\n",
    "counts = clust_beta_df.groupby('ClusterID').count().iloc[:,0]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_cluster(df, var_name, order):\n",
    "\n",
    "    df[var_name] = df[var_name].replace(order)\n",
    "    df[var_name] = df[var_name].str.lstrip('Class_')\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode values in order of adversity exposure (lowest to highest)\n",
    "\n",
    "order_dict = {0:'Class_3', 1:'Class_2', 2:'Class_1'}\n",
    "group_df=recode_cluster(group_df_orig, 'ClusterID', order_dict) \n",
    "group_df = pd.merge(group_df, all_coll_df.reset_index(), on='Subject', how ='inner', suffixes = (None, 'neural'))\n",
    "group_df['ClusterID'] = group_df['ClusterID'].astype(int)\n",
    "\n",
    "# # Write df to CSV\n",
    "group_df_file = analysis + '/Analysis_Dataset_LPA_3class_n={}_{}.csv'.format(len(group_df), today)\n",
    "group_df.to_csv(group_df_file)\n",
    "print(group_df_file)\n",
    "\n",
    "# Print counts\n",
    "counts = group_df.groupby('ClusterID').count().iloc[:,0]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5a4e2-bf72-4c4c-b054-2412e90e478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set order and categories for all plots\n",
    "\n",
    "import itertools\n",
    "# Get category IDs, sort, put in list\n",
    "clus_cats = pd.DataFrame(group_df['ClusterID'].value_counts()).index.astype(int).sort_values().tolist()\n",
    "\n",
    "# Create list of pairwise combinations\n",
    "pair_cats=[]\n",
    "for each in itertools.combinations(clus_cats, 2):\n",
    "    pair_cats.append(each)\n",
    "\n",
    "# Define for subsequent plots\n",
    "order = clus_cats\n",
    "pairs = pair_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_network(df, atlas_defs, network_val):\n",
    "#     func_net_inds = np.where(atlas_defs.iloc[0,:].to_numpy() == network_val) # Get indices of column\n",
    "#     func_net = df.iloc[:,func_net_inds[0].tolist()] # Subset columns by those indices\n",
    "#     return func_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in network definitions\n",
    "# atlas_definitions = pd.read_csv('/gpfs/milgram/pi/gee_dylan/lms233/Shen368/Shen_TenNetwork_368atlas.txt', header=None, sep='\\t', index_col=None)\n",
    "# at_subset = atlas_definitions.iloc[:,0:341]\n",
    "# at_subset.columns = range(1,342) # Rename columns to account for 0-index\n",
    "\n",
    "# def compute_net_data(regressed_nets, thde, atlas_subset):\n",
    "    \n",
    "#     func_net1 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 1).mean(axis=1), columns = ['net_1_{}'.format(thde)])\n",
    "#     func_net2 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 2).mean(axis=1), columns = ['net_2_{}'.format(thde)])\n",
    "#     func_net3 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 3).mean(axis=1), columns = ['net_3_{}'.format(thde)])\n",
    "#     func_net4 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 4).mean(axis=1), columns = ['net_4_{}'.format(thde)])\n",
    "#     func_net5 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 5).mean(axis=1), columns = ['net_5_{}'.format(thde)])\n",
    "#     func_net6 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 6).mean(axis=1), columns = ['net_6_{}'.format(thde)])\n",
    "#     func_net7 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 7).mean(axis=1), columns = ['net_7_{}'.format(thde)])\n",
    "#     func_net8 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 8).mean(axis=1), columns = ['net_8_{}'.format(thde)])\n",
    "#     func_net9 = pd.DataFrame(get_network(regressed_nets, atlas_subset, 9).mean(axis=1), columns = ['net_9_{}'.format(thde)])\n",
    "#     # func_net10 = get_network(tvs_full, at_subset, 10).mean(axis=1) # Exclude bc all cerebellar nodes\n",
    "    \n",
    "#     # Combine dfs into one\n",
    "#     func_net_df = zscore(pd.concat([func_net1, func_net2,\n",
    "#                              func_net3, func_net4, func_net5,\n",
    "#                              func_net6, func_net7, func_net8,\n",
    "#                              func_net9], axis=1), axis=0)\n",
    "#     return func_net_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50df2d-5309-48ca-b726-9acea1addd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get network data for each contrast\n",
    "# thr_func_net = compute_net_data(threat_reg_df_shen, 'thr', at_subset)\n",
    "# saf_func_net = compute_net_data(safety_reg_df_shen, 'saf', at_subset)\n",
    "# tvs_func_net = compute_net_data(tvs_reg_df_shen, 'tvs', at_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b5393-b4d5-49bf-9152-111cb6070fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create network df\n",
    "# net_df= pd.merge(group_df, tvs_func_net, on='Subject')\n",
    "# thrsaf_netdf = pd.merge(thr_func_net, saf_func_net, on='Subject')\n",
    "# all_func_nets_df = pd.merge(net_df, thrsaf_netdf, on='Subject')\n",
    "\n",
    "# net_dvars = ['net_1_tvs', 'net_2_tvs', 'net_3_tvs',\n",
    "#              'net_4_tvs', 'net_5_tvs', 'net_6_tvs', 'net_7_tvs',\n",
    "#              'net_8_tvs', 'net_9_tvs']\n",
    "\n",
    "# fdr_list = []\n",
    "# for i, yvar in enumerate(net_dvars):\n",
    "#     xvar = net_df[['ClusterID', \n",
    "#                        'sex', 'asr_age', \n",
    "#                        'combined_income', 'years_education']]\n",
    "#     xvar['ClusterID'] = xvar['ClusterID'].astype('int')\n",
    "#     xmat = sm.add_constant(xvar)\n",
    "    \n",
    "#     net_model = smf.ols(\"{} ~ C(ClusterID) + sex + asr_age + combined_income + years_education\".format(yvar), data=net_df).fit()\n",
    "    \n",
    "#     table=sm.stats.anova_lm(net_model, type='3', robust='hc3')\n",
    "#     display(table)\n",
    "#     fdr_list.append(table['PR(>F)']['C(ClusterID)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statannotations as sa\n",
    "# fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize = (12, 8))\n",
    "# sns.set_palette('Paired')\n",
    "\n",
    "# from statannotations.Annotator import Annotator\n",
    "\n",
    "\n",
    "# x = \"ClusterID\"\n",
    "\n",
    "# axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9]\n",
    "\n",
    "# dvars = ['net_1_tvs', 'net_2_tvs', 'net_3_tvs',\n",
    "#          'net_4_tvs', 'net_5_tvs', 'net_6_tvs', 'net_7_tvs',\n",
    "#          'net_8_tvs', 'net_9_tvs']\n",
    "\n",
    "# labels = ['Functional Network 1', 'Functional Network 2', 'Functional Network 3',\n",
    "#           'Functional Network 4', 'Functional Network 5', 'Functional Network 6', \n",
    "#           'Functional Network 7', 'Functional Network 8', 'Functional Network 9']\n",
    "\n",
    "# titles = ['Medial frontal network', 'Frontoparietal network', 'Default mode network',\n",
    "#           'Motor network', 'Visual I network', 'Visual II network', \n",
    "#           'Visual association network', 'Cingulo-opercular network', 'Subcortical network']\n",
    "\n",
    "# for i in range(0, len(dvars)):\n",
    "#     y = dvars[i]\n",
    "#     sns.boxplot(y=y, x=x, ax = axes[i], data=net_df) #order=order, \n",
    "#     sns.stripplot(y=y, x=x, data = net_df, edgecolor='black', linewidth = 0.5, ax = axes[i]) #order=order, \n",
    "#     axes[i].set_ylabel(labels[i], size=10)\n",
    "#     axes[i].set_xlabel('Latent Profile', size=10)\n",
    "#     axes[i].set_title(titles[i], size=15)\n",
    "#     # axes[i].set_ylim(-2, 4)\n",
    " \n",
    "#     annotator = Annotator(axes[i], pairs, data=net_df, x=x, y=y, order=order)\n",
    "#     annotator.configure(test='t-test_ind', text_format='star', loc='inside')\n",
    "#     annotator.apply_and_annotate()\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46543e0a-bb5c-4590-b032-f0278af8f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ((ax1, ax2, ax3)) = plt.subplots( 1, 3, figsize = (16, 4))\n",
    "\n",
    "# from statannotations.Annotator import Annotator\n",
    "# df= all_func_nets_df\n",
    "# x = \"ClusterID\"\n",
    "\n",
    "# order = clus_cats\n",
    "# pairs = pair_cats\n",
    "\n",
    "# axes = [ax1, ax2, ax3, ax4, ax5, ax6, \n",
    "#         ax7, ax8, ax9, ax10, ax11, ax12, \n",
    "#         ax13, ax14, ax15, ax16, ax17, ax18]\n",
    "\n",
    "# dvars = [ \"net_3_tvs\", \"net_3_thr\", \"net_3_saf\"]\n",
    "\n",
    "\n",
    "# labels2 = ['Default Mode Network\\nThreat vs. Safety', \n",
    "#            'Default Mode Network\\nThreat vs. Baseline', \n",
    "#            'Default Mode Network\\nSafety vs. Baseline']\n",
    "\n",
    "# thr_subcort_palette = ['#6f89a2', '#a16527', '#784050']\n",
    "# thr_subcort_palette_point = ['#8fb1d0', '#cf8232', '#965064']\n",
    "\n",
    "# saf_subcort_palette = ['#c5dcf1', '#f0bd87', '#c096a2']\n",
    "# saf_subcort_palette_point = ['#d8e7f5', '#f5d3af', '#d5b9c1']\n",
    "\n",
    "# tvs_subcort_palette = ['#9fc5e8', '#e69138', '#965064']\n",
    "# tvs_subcort_palette_point = ['#b2d0ec', '#eba75f', '#e58080']\n",
    "\n",
    "# for i in range(0, len(dvars)):\n",
    "#     y = dvars[i]\n",
    "#     if '_thr' in y:\n",
    "#         plotpalette = thr_subcort_palette\n",
    "#         plotpointpal = thr_subcort_palette_point\n",
    "#     elif '_saf' in y:\n",
    "#         plotpalette = saf_subcort_palette\n",
    "#         plotpointpal = saf_subcort_palette_point\n",
    "#     elif '_tvs' in y:\n",
    "#         plotpalette = tvs_subcort_palette\n",
    "#         plotpointpal = tvs_subcort_palette_point\n",
    "#     else:\n",
    "#         print ('Error! Could not identify dvar palette to use')\n",
    "        \n",
    "#     sns.boxplot(data=df, x=x, y=y,  ax = axes[i], palette=plotpalette) #order=order,\n",
    "#     sns.stripplot(y=y, x=x,  data = df, edgecolor='black',  linewidth = 0.5, ax = axes[i], palette=plotpointpal) #order=order,\n",
    "#     axes[i].set_ylabel(labels2[i], size=14)\n",
    "#     axes[i].set_xlabel('Latent Profile', size=14)\n",
    "#     # axes[i].set_ylim(-2, 7)\n",
    "    \n",
    "#     annotator = Annotator(axes[i], pairs, data=df, x=x, y=y, order=order)\n",
    "#     annotator.configure(test='t-test_ind', text_format='star', loc='inside')\n",
    "#     annotator.apply_and_annotate()\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.savefig(analysis + '/Figures/LCDiffs_FuncNetworks_{}.png'.format(today), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964c206-f9d5-4cd5-b3c6-865326f4031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Anovas comparing differences\n",
    "# from statsmodels.formula.api import ols\n",
    "\n",
    "# dvars = ['net_3_tvs', 'net_3_thr', 'net_3_saf']\n",
    "\n",
    "# for i in range(0, len(dvars)):\n",
    "#     printmd('**{}**'.format(dvars[i]))\n",
    "#     df = pairwise_tests(data = all_func_nets_df, between = 'ClusterID', dv = dvars[i], parametric=True, subject = 'Subject', padjust='fdr_bh', effsize='cohen', return_desc=True)\n",
    "#     display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-translator",
   "metadata": {},
   "source": [
    "### Plot points to examine clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Plot dimensionality reduced data\n",
    "pca = PCA(n_components = 3, \n",
    "         random_state=0).fit_transform(in_beta_mat)\n",
    "tsne_fit = TSNE(n_components = 2,\n",
    "               init = 'random',\n",
    "                random_state=0,\n",
    "               n_iter=3000).fit_transform(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = pd.DataFrame(tsne_fit, columns = ['Dimension 1', 'Dimension 2'])\n",
    "embed_df['ClusterID'] = group_df['ClusterID']\n",
    "\n",
    "sns.scatterplot(x = 'Dimension 1', y = 'Dimension 2', hue = 'ClusterID', data = embed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-answer",
   "metadata": {},
   "source": [
    "### Plot hippocampal, amygdalar, and adversity data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f5dd9-b25e-42bb-85df-d55b148be2b0",
   "metadata": {},
   "source": [
    "**Mackey segmentations** \\\n",
    "Mackey Area 14c: Majority Frontal Orbital Cortex and Subcallosal Cortex \\\n",
    "Mackey Area 24: Majority Frontal Medial Cortex and Subcallosal Cortex \\\n",
    "Mackey Area 25: Majority Subcallosal Cortex and Frontal Orbital Cortex \\\n",
    "\\\n",
    "**PCA components**\\\n",
    "Mackey_14r_14rr_11m_PCA: Majority Frontal Pole, Frontal Orbital Cortex, and Frontal Medial Cortex \\\n",
    "Mackey_14m_32_PCA: Majority Subcallosal Cortex, Anterior Cingulate Gyrus, and Paracingulate Gyrus\n",
    "\n",
    "Mackey Area 11m: Majority Frontal Pole, Frontal Medial Cortex, and Frontal Orbital Cortex \\\n",
    "Mackey Area 14r: Majority Frontal Orbital Cortex, Subcallosal Cortex, and Frontal Medial Cortex \\\n",
    "Mackey Area 14rr: Majority Frontal Orbital Cortex, Majority Frontal Pole, and Frontal Medial Cortex \\\n",
    "Mackey Area 14m: Majority Frontal Medial Cortex, Subcallosal Cortex, Paracingulate Gyrus, and Frontal Pole \\\n",
    "Mackey Area 32: Majority Anterior Cingulate Gyrus, Paracingulate Gyrus, and Subcallosal Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c75176-ccc2-488d-bbdb-fd753110b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3, ax4, ax5, ax6), \n",
    "      (ax7, ax8, ax9, ax10, ax11, ax12),\n",
    "      (ax13, ax14, ax15, ax16, ax17, ax18)) = plt.subplots( 3, 6, figsize = (20,10))\n",
    "\n",
    "from statannotations.Annotator import Annotator\n",
    "df= group_df\n",
    "x = \"ClusterID\"\n",
    "\n",
    "order = clus_cats\n",
    "pairs = pair_cats\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6, \n",
    "        ax7, ax8, ax9, ax10, ax11, ax12, \n",
    "        ax13, ax14, ax15, ax16, ax17, ax18]\n",
    "\n",
    "dvars = [ \"hipp_tvs\", \"amyg_tvs\", 'Mackey_24_tvs', \n",
    "         \"Mackey_25_tvs\", 'Mackey_32_14m_tvs', \n",
    "         '{}_dACC_tvs'.format(dacc_roi), \n",
    "         \n",
    "          \"hipp_thr\", \"amyg_thr\", 'Mackey_24_thr',\n",
    "         \"Mackey_25_thr\", 'Mackey_32_14m_thr', \n",
    "         '{}_dACC_thr'.format(dacc_roi),\n",
    "         \n",
    "         \"hipp_saf\", \"amyg_saf\", 'Mackey_24_saf', \n",
    "         \"Mackey_25_saf\", 'Mackey_32_14m_saf', \n",
    "         '{}_dACC_saf'.format(dacc_roi), \n",
    "        ]\n",
    "\n",
    "labels2 = ['Hippocampus\\nThreat vs. Safety', 'Amygdala\\nThreat vs. Safety', 'vmPFC Area 24\\nThreat vs. Safety', \n",
    "           'vmPFC Area 25\\nThreat vs. Safety', 'vmPFC Areas 32 & 14m\\nThreat vs. Safety', \n",
    "           '{} dACC\\nThreat vs. Safety'.format(dacc_roi), \n",
    "           \n",
    "           'Hippocampus\\nThreat vs. Baseline', 'Amygdala\\nThreat vs. Baseline','vmPFC Area 24\\nThreat vs. Baseline', \n",
    "           'vmPFC Area 25\\nThreat vs. Baseline', 'vmPFC Areas 32 & 14m\\nThreat vs. Baseline', \n",
    "           '{} dACC\\nThreat vs. Baseline'.format(dacc_roi), \n",
    "        \n",
    "           'Hippocampus\\nSafety vs. Baseline', 'Amygdala\\nSafety vs. Baseline','vmPFC Area 24\\nSafety vs. Baseline', \n",
    "           'vmPFC Area 25\\nSafety vs. Baseline', 'vmPFC Areas 32 & 14m\\nSafety vs. Baseline', \n",
    "           '{} dACC\\nSafety vs. Baseline'.format(dacc_roi)]\n",
    "\n",
    "\n",
    "plotpalette = ['#9fc5e8', '#e69138', '#965064']\n",
    "plotpointpal = ['#b2d0ec', '#eba75f', '#e58080']\n",
    "\n",
    "for i in range(0, len(dvars)):\n",
    "    y = dvars[i]\n",
    "        \n",
    "    sns.boxplot(data=df, x=x, y=y,  ax = axes[i], palette=plotpalette) #order=order,\n",
    "    sns.stripplot(y=y, x=x,  data = df, edgecolor='black',  linewidth = 0.5, ax = axes[i], palette=plotpointpal) #order=order,\n",
    "    axes[i].set_ylabel(labels2[i], size=14)\n",
    "    axes[i].set_xlabel('Latent Profile', size=14)\n",
    "    # axes[i].set_ylim(-2, 7)\n",
    "    \n",
    "    annotator = Annotator(axes[i], pairs, data=df, x=x, y=y, order=order)\n",
    "    annotator.configure(test='t-test_ind', text_format='star', loc='inside')\n",
    "    annotator.apply_and_annotate()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(analysis + '/Figures/LCDiffs_PFC_{}.png'.format(today), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735f471-db77-456e-9990-cc6dc220982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LCDiffs_PFC_{}.png'.format(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294a8c0-3197-40c3-b12b-ca616f736c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert to long format\n",
    "# Hipp\n",
    "hipp_long = pd.melt(group_df[[\"Subject\", \"ClusterID\", \"hipp_saf\", \"hipp_thr\"]], \n",
    "                    id_vars = ['Subject','ClusterID'], var_name = 'thr_vs_saf', value_name = 'hipp_act')\n",
    "hipp_long['thr_vs_saf'] = hipp_long['thr_vs_saf'].str.split('_', expand=True)[1]\n",
    "\n",
    "# Amyg\n",
    "amyg_long = pd.melt(group_df[[\"Subject\", \"ClusterID\", \"amyg_saf\", \"amyg_thr\"]], \n",
    "                    id_vars = ['Subject','ClusterID'], var_name = 'thr_vs_saf', value_name = 'amyg_act')\n",
    "amyg_long['thr_vs_saf'] = amyg_long['thr_vs_saf'].str.split('_', expand=True)[1]\n",
    "\n",
    "# vmPFC 25\n",
    "m25_long = pd.melt(group_df[[\"Subject\", \"ClusterID\", \"Mackey_25_saf\", \"Mackey_25_thr\"]], \n",
    "                   id_vars = ['Subject','ClusterID'], var_name = 'thr_vs_saf', value_name = 'm25_act') \n",
    "m25_long['thr_vs_saf'] = m25_long['thr_vs_saf'].str.split('_', expand=True)[2]\n",
    "\n",
    "# vmPFC 24\n",
    "m24_long = pd.melt(group_df[[\"Subject\", \"ClusterID\", \"Mackey_24_saf\", \"Mackey_24_thr\"]], \n",
    "                   id_vars = ['Subject','ClusterID'], var_name = 'thr_vs_saf', value_name = 'm24_act') \n",
    "m24_long['thr_vs_saf'] = m24_long['thr_vs_saf'].str.split('_', expand=True)[2]\n",
    "\n",
    "# vmPFC 32 + 14m\n",
    "m32_long = pd.melt(group_df[[\"Subject\", \"ClusterID\", \"Mackey_32_14m_saf\", \"Mackey_32_14m_thr\"]], \n",
    "                   id_vars = ['Subject','ClusterID'], var_name = 'thr_vs_saf', value_name = 'm32_act') \n",
    "m32_long['thr_vs_saf'] = m32_long['thr_vs_saf'].str.split('_', expand=True)[3]\n",
    "\n",
    "# dACC\n",
    "dacc_long = pd.melt(group_df[[\"Subject\", \"ClusterID\", \"{}_dACC_saf\".format(dacc_roi), \"{}_dACC_thr\".format(dacc_roi)]], \n",
    "                    id_vars = ['Subject','ClusterID'], var_name = 'thr_vs_saf', value_name = 'dacc_act') \n",
    "dacc_long['thr_vs_saf'] = dacc_long['thr_vs_saf'].str.split('_', expand=True)[2]\n",
    "\n",
    "# Merge data\n",
    "m1 = pd.merge(hipp_long, amyg_long, how = 'inner', on=['Subject', \"ClusterID\", 'thr_vs_saf'])\n",
    "m2 = pd.merge(m1, m25_long, how = 'inner', on=['Subject', \"ClusterID\", 'thr_vs_saf'])\n",
    "m3 = pd.merge(m2, m24_long, how = 'inner', on=['Subject', \"ClusterID\", 'thr_vs_saf'])\n",
    "m4 = pd.merge(m3, m32_long, how = 'inner', on=['Subject', \"ClusterID\", 'thr_vs_saf'])\n",
    "m5 = pd.merge(m4, dacc_long, how = 'inner', on=['Subject', \"ClusterID\", 'thr_vs_saf'])\n",
    "all_long = m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0498a-0cdb-4a77-9d64-7eb9104fdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print pairwise differences -- are neural responses to threat and safety statistically different within clusters (T-tests)\n",
    "\n",
    "dvars = ['hipp', 'amyg', 'Mackey_25', 'Mackey_24', 'Mackey_32_14m', 'AAL3_dACC', ]\n",
    "\n",
    "print('*** ONE SAMPLE T_TESTS ***')\n",
    "res = pd.DataFrame()\n",
    "for i, dvar in enumerate(dvars):\n",
    "    res_df = pd.DataFrame()\n",
    "    for j, cluster in enumerate(clus_cats):\n",
    "        clus_df = group_df[group_df['ClusterID'] == cluster].reset_index(drop=True)\n",
    "        df = ttest(x = clus_df['{}_tvs'.format(dvar)], y=0, alternative = \"two-sided\") # Two-sided one-sample T-test       \n",
    "        df['mean (A)'] = clus_df['{}_tvs'.format(dvar)].mean()\n",
    "        df['std (A)'] = clus_df['{}_tvs'.format(dvar)].std()\n",
    "        res_df = pd.concat([res_df, df], axis=0)\n",
    "    printmd('**{}**'.format(dvars[i]))\n",
    "    res_df.index = ['Cluster 1', 'Cluster 2', 'Cluster 3']\n",
    "    res_df['pFDR'] = fdr(res_df['p-val'])[1]\n",
    "    res_df = res_df.round(3)\n",
    "    res_df_reordered = res_df[['mean (A)', 'std (A)', 'T', 'dof','p-val', 'pFDR', 'cohen-d']]\n",
    "    display(res_df_reordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e55b6-d9cc-4843-903d-d643e23f78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print pairwise differences between groups -- are clusters statistically different in response to threat\n",
    "dvars = [\"hipp_thr\", \"amyg_thr\", 'Mackey_24_thr', \"Mackey_25_thr\", 'Mackey_32_14m_thr', '{}_dACC_thr'.format(dacc_roi),\n",
    "         \"hipp_saf\", \"amyg_saf\", \"Mackey_24_saf\", 'Mackey_25_saf', 'Mackey_32_14m_saf', '{}_dACC_saf'.format(dacc_roi),\n",
    "         \"hipp_tvs\", \"amyg_tvs\",\"Mackey_24_tvs\", 'Mackey_25_tvs', 'Mackey_32_14m_tvs', '{}_dACC_tvs'.format(dacc_roi)\n",
    "        ]\n",
    "\n",
    "res = pd.DataFrame()\n",
    "for i in range(0, len(dvars)):\n",
    "    df = pairwise_gameshowell(data = group_df, between = 'ClusterID', \n",
    "                              dv = dvars[i], \n",
    "                         effsize='cohen').round(3)\n",
    "    std_df = pairwise_tests(data=group_df, between='ClusterID', dv = dvars[i], parametric=True, return_desc=True) # Compute pairwise tests for within-group means/std\n",
    "    df['Group'] = dvars[i]\n",
    "    printmd('**{}**'.format(dvars[i]))\n",
    "    df = pd.concat([df, std_df[['std(A)', 'std(B)']]], axis=1) # Concatenate means/std dev\n",
    "    display(df)\n",
    "    res = pd.concat([res, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot outputs\n",
    "fig, ((ax1, ax2, ax3, ax4)) = plt.subplots(1, 4, figsize = (16, 4))\n",
    "sns.set_palette('Paired')\n",
    "\n",
    "x = \"ClusterID\"\n",
    "\n",
    "order = clus_cats\n",
    "pairs = pair_cats\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "dvars = [\"Early_Childhood_regr\",\n",
    "         \"Mid_Childhood_regr\", \n",
    "         \"Adolescence_regr\", \n",
    "         \"Adulthood_regr\"]\n",
    "\n",
    "adv_labels = ['Adversity Exposure in\\nEarly Childhood ', \n",
    "              'Adversity Exposure in\\nMiddle Childhood', \n",
    "              'Adversity Exposure\\nin Adolescence', \n",
    "              'Adversity Exposure\\nin Adulthood', \n",
    "              'Cumulative Exposure\\nto Developmental Adversity',\n",
    "              'Cumulative Exposure\\nto Adversity']\n",
    "\n",
    "pairwise_dvars = [\"Early_Childhood\",\n",
    "                  \"Mid_Childhood\", \n",
    "                  \"Adolescence\",\n",
    "                 \"Adulthood\"]\n",
    "\n",
    "adv_colors = ['#9fc5e8', '#e69138', '#965064']\n",
    "adv_pointcols = ['#b2d0ec', '#eba75f', '#bc647e']\n",
    "\n",
    "for i in range(0, len(dvars)):\n",
    "    y = dvars[i]\n",
    "    y_raw = pairwise_dvars[i]\n",
    "    print(y)\n",
    "    # Filter dependent var so only values greater than 0 remain\n",
    "    df = group_df\n",
    "\n",
    "    # Print medians\n",
    "    print('*** Class 1 Exposure Median: {}; Mean: {}, Std Dev: {}, range = {}-{} ***\\n'.format(df[df.ClusterID==1][y_raw].median(),\n",
    "                                                            df[df.ClusterID==1][y].mean(), df[df.ClusterID==1][y].std(), df[df.ClusterID==1][y_raw].min(), \n",
    "                                                                                               df[df.ClusterID==1][y_raw].max()))\n",
    "    print('*** Class 2 Exposure Median: {}; Mean: {}, Std Dev: {}, range = {}-{} ***\\n'.format(df[df.ClusterID==2][y_raw].median(),\n",
    "                                                            df[df.ClusterID==2][y].mean(), df[df.ClusterID==2][y].std(), df[df.ClusterID==2][y_raw].min(), \n",
    "                                                                                               df[df.ClusterID==2][y_raw].max()))\n",
    "    print('*** Class 3 Exposure Median: {}; Mean: {}, Std Dev: {}, range = {}-{} ***\\n'.format(df[df.ClusterID==3][y_raw].median(),\n",
    "                                                            df[df.ClusterID==3][y].mean(), df[df.ClusterID==3][y].std(), df[df.ClusterID==3][y_raw].min(), \n",
    "                                                                                               df[df.ClusterID==3][y_raw].max()))\n",
    "    \n",
    "\n",
    "    sns.boxplot(data=df, x=x, y=y, ax = axes[i], palette=adv_colors)\n",
    "    sns.stripplot(y=y, x=x, data = df, edgecolor='black', linewidth = 0.5, ax = axes[i], jitter=True, \n",
    "                  palette=adv_pointcols)\n",
    "    \n",
    "    axes[i].set_ylabel('Number of Exposures', size=14)\n",
    "    axes[i].set_xlabel('Latent Profile', size=14)\n",
    "    axes[i].set_ylim(-2, 7)\n",
    "    annotator = Annotator(axes[i], pairs, data=df, x=x, y=y, order=order)\n",
    "    annotator.configure(test='Mann-Whitney', text_format='star', loc='inside')\n",
    "    annotator.apply_and_annotate()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(analysis + '/Figures/LCDiffs_AdversityExp_{}.png'.format(today), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042b528-9ea3-4791-9e01-0e782b6346f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = []\n",
    "p_2 = []\n",
    "p_3 = []\n",
    "\n",
    "def get_desc_stats(data_df, vars_list):\n",
    "    append_df = np.zeros((3, 8), dtype='object')\n",
    "   \n",
    "    for i, cat in enumerate(clus_cats):\n",
    "        df = data_df[data_df['ClusterID'] == cat]\n",
    "        assert len(df['ClusterID']) < len(group_df)\n",
    "        counter = []\n",
    "        \n",
    "        for j, var in enumerate(vars_list):\n",
    "            loc = j + sum(counter)\n",
    "            med = df[var].median()\n",
    "            var_min, var_max = round(df[var].min()), round(df[var].max())\n",
    "            \n",
    "            append_df[i, loc] = med\n",
    "            append_df[i, loc+1] = \"{}-{}\".format(var_min, var_max)\n",
    "            counter.append(1)\n",
    "\n",
    "    return append_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c4a74-fcd7-4ff8-9021-2276cf1b7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_list = ['Early_Childhood', 'Mid_Childhood', 'Adolescence', 'Adulthood']\n",
    "adv_summary = get_desc_stats(group_df, adv_list)\n",
    "pd.DataFrame(adv_summary, columns = ['Median', 'Range', 'Median', 'Range', \n",
    "                                    'Median', 'Range', 'Median', 'Range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fceff-cc8d-4428-8c6e-2d45ff4959cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine pairwise differences between groups in early childhood adversity exposure\n",
    "ec_ptests = pairwise_tests(data = group_df, between = 'ClusterID', dv = 'Early_Childhood_regr', parametric=False, return_desc=True, subject = 'Subject', padjust='fdr_bh', effsize='cohen').round(3)\n",
    "ec_ptests['Group'] = 'Early Childhood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40500e74-0c71-42e4-8265-c5d3315c4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine pairwise differences between groups in middle childhood adversity exposure\n",
    "mc_ptests = pairwise_tests(data = group_df, between = 'ClusterID', dv = 'Mid_Childhood_regr', parametric=False, return_desc=True, subject = 'Subject', padjust='fdr_bh', effsize='cohen').round(3)\n",
    "mc_ptests['Group'] = 'Middle Childhood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933bed2-80bb-4dca-8a53-67f37efde710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine pairwise differences between groups in adolescent adversity exposure\n",
    "adol_ptests = pairwise_tests(data = group_df, between = 'ClusterID', dv = 'Adolescence_regr', parametric=False, return_desc=True, subject = 'Subject', padjust='fdr_bh', effsize='cohen').round(3)\n",
    "adol_ptests['Group'] = 'Adolescence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a681391-88c3-4d9e-ac3d-1934b550e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine pairwise differences between groups in adolescent adversity exposure\n",
    "adult_ptests = pairwise_tests(data = group_df, between = 'ClusterID', dv = 'Adulthood_regr', parametric=False, return_desc=True, subject = 'Subject', padjust='fdr_bh', effsize='cohen').round(3)\n",
    "adult_ptests['Group'] = 'Adulthood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4095e8-bc22-408d-9d36-ef5333800e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate into table\n",
    "adv_table = pd.concat([ec_ptests, mc_ptests, adol_ptests, adult_ptests], axis=0).drop(['Contrast', 'alternative', 'p-adjust', 'Paired', 'Parametric'], axis=1).rename(columns = {'U-val': 'Statistic', 'p-unc':'pval'})\n",
    "tvs_table = res[res['Group'].str.endswith('tvs')].rename(columns = {'T':'Statistic'})\n",
    "both_table = pd.concat([adv_table, tvs_table], axis = 0)\n",
    "both_table['Comparison'] = both_table['A'].astype(str) + ' vs. ' + both_table['B'].astype(str)\n",
    "both_table = both_table.drop(['A', 'B'], axis=1)[[\"Group\", 'Comparison', \"mean(A)\", \"std(A)\", \"mean(B)\", \"std(B)\", 'Statistic', 'pval', 'p-corr', 'cohen']]\n",
    "both_table.pivot_table(columns = ['Group', 'Comparison'], sort=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a70018-6e2c-4c6e-a28d-e57ca88af0da",
   "metadata": {},
   "source": [
    "### Examine group differences in symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862e4a2-7ab9-4d31-a170-e8ef51f83e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Symptom Data\n",
    "symptom_df = group_df.dropna(subset = ['age_at_ri', 'sex', 'combined_income', 'years_education', 'total_scared'])\n",
    "print('{} subjects have symptom data'.format(len(symptom_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model associations with anxiety symptoms\n",
    "symp_pvals = []\n",
    "\n",
    "# Set dependent variable\n",
    "symptom_df['scared_total_tranf'] = np.sqrt(symptom_df['total_scared'] + 1)\n",
    "yvar = 'scared_total_tranf'\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "sns.histplot(symptom_df[yvar], ax=ax, bins=30)\n",
    "plt.show()\n",
    "\n",
    "# Fit model\n",
    "scared_model = smf.ols(\"scared_total_tranf ~ C(ClusterID) + sex + asr_age + combined_income + years_education \", data=symptom_df).fit()\n",
    "display(scared_model.summary())\n",
    "table=sm.stats.anova_lm(scared_model, type='3', robust='hc3') #https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf, \"...which arrive at the conclusion that HC3 provides the best performance in small samples as it gives less weight to influential observations.\"\n",
    "symp_pvals.append([yvar,table[\"PR(>F)\"]['C(ClusterID)']])\n",
    "display(table)\n",
    "\n",
    "# Plot results\n",
    "order = clus_cats\n",
    "pairs = pair_cats\n",
    "\n",
    "# Print median values for each class\n",
    "print('*** Class 1 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==1]['total_scared'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==1]['total_scared'].mean()))\n",
    "print('*** Class 2 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==2]['total_scared'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==2]['total_scared'].mean()))\n",
    "print('*** Class 3 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==3]['total_scared'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==3]['total_scared'].mean()))\n",
    "# print('*** Class 4 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==4]['total_scared'].median(),\n",
    "#                                                         symptom_df[symptom_df.ClusterID==4]['total_scared'].mean()))\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 3))\n",
    "anx_boxpal = ['#9fc5e8', '#e69138', '#965064']\n",
    "anx_boxpalpoint = ['#b2d0ec', '#eba75f', '#bc647e']\n",
    "\n",
    "sns.boxplot(x = 'ClusterID', y = yvar, data = symptom_df, ax=ax, palette=anx_boxpal)\n",
    "sns.stripplot(y=yvar, x='ClusterID', data = symptom_df, edgecolor='black', order=order, linewidth = 0.5, ax = ax,\n",
    "             palette=anx_boxpalpoint)\n",
    "ax.set_ylabel('Anxiety Symptoms (SCAARED)')\n",
    "ax.set_xlabel('Latent Profile')\n",
    "ax.set_ylim(0,16)\n",
    "\n",
    "annotator = Annotator(ax, pairs, data=symptom_df, x='ClusterID', y=yvar, order=order)\n",
    "annotator.configure(test='Mann-Whitney', text_format='star', loc='inside')\n",
    "annotator.apply_and_annotate()\n",
    "plt.tight_layout()\n",
    "plt.savefig(analysis + '/Figures/LCDiffs_Anxiety_{}.png'.format(today), dpi=300, transparent=True)\n",
    "plt.show()\n",
    "from pingouin import pairwise_tests\n",
    "pairwise_gameshowell(data = symptom_df, between = 'ClusterID', dv = yvar, #subject = 'Subject', parametric=True, padjust='fdr_bh',, return_desc=True\n",
    "                         effsize='cohen').round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4289a0-ce65-4a65-bbf7-370f2d37c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model associations with anxious and depressive symptoms\n",
    "\n",
    "# Model Total symptoms\n",
    "symptom_df['tsc_tranf'] = np.log(symptom_df['tsc_total'] + 1) \n",
    "yvar = 'tsc_tranf' #Square root transform bc not normal (JB test)\n",
    "print(\"Mean: {}\".format(symptom_df[yvar].mean()))\n",
    "print(\"Variance: {}\".format(symptom_df[yvar].var()))\n",
    "\n",
    "# Histogram of distribution\\\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "sns.histplot(symptom_df[yvar], ax=ax, bins=30)\n",
    "plt.show()\n",
    "\n",
    "# Fit model\n",
    "tsc_model = smf.ols(\"tsc_tranf ~ C(ClusterID) + sex + asr_age + combined_income + years_education \", data=symptom_df).fit()\n",
    "table=sm.stats.anova_lm(tsc_model, type='3', robust='hc3')\n",
    "symp_pvals.append([yvar,table[\"PR(>F)\"]['C(ClusterID)']])\n",
    "display(table)\n",
    "\n",
    "# Print class medians\n",
    "print('*** Class 1 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==1]['tsc_total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==1]['tsc_total'].mean()))\n",
    "print('*** Class 2 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==2]['tsc_total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==2]['tsc_total'].mean()))\n",
    "print('*** Class 3 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==3]['tsc_total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==3]['tsc_total'].mean()))\n",
    "\n",
    "order = clus_cats\n",
    "pairs = pair_cats\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 3))\n",
    "\n",
    "sns.boxplot(x = 'ClusterID', y = 'tsc_total', data = symptom_df,ax=ax, palette=\"blend:#f6b26b,#df6161\")\n",
    "sns.stripplot(y='tsc_total', x='ClusterID',data = symptom_df, edgecolor='black', order=order, linewidth = 0.5, ax = ax,\n",
    "             palette=\"blend:#f6b26b,#df6161\")\n",
    "annotator = Annotator(ax=ax, pairs = pairs, data=symptom_df, x=x, y = 'tsc_total', order=order)\n",
    "annotator.configure(test='Mann-Whitney', text_format='star', loc='inside')\n",
    "annotator.apply_and_annotate()\n",
    "plt.show()\n",
    "pairwise_gameshowell(data = symptom_df, dv = yvar, between = 'ClusterID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66327d9c-59b2-4f2d-a287-67698ab4f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model associations with anxious and depressive symptoms\n",
    "print(len(symptom_df))\n",
    "# Model Total symptoms\n",
    "symptom_df['ext_prob_tranf'] = np.log(symptom_df['Externalizing_Problems_Total'] + 1) #Log root transform bc not normal (JB test)\n",
    "yvar = 'ext_prob_tranf'\n",
    "print(\"Mean: {}\".format(symptom_df[yvar].mean()))\n",
    "print(\"Variance: {}\".format(symptom_df[yvar].var()))\n",
    "\n",
    "# Histogram of distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "sns.histplot(symptom_df[yvar], ax=ax, bins=30)\n",
    "plt.show()\n",
    "\n",
    "# Fit model\n",
    "ext_model = smf.ols(\"ext_prob_tranf ~ C(ClusterID) + sex + asr_age + combined_income + years_education \", data=symptom_df).fit()\n",
    "table=sm.stats.anova_lm(ext_model, type='3', robust='hc3')\n",
    "symp_pvals.append([yvar,table[\"PR(>F)\"]['C(ClusterID)']])\n",
    "display(ext_model.summary())\n",
    "display(table)\n",
    "\n",
    "# Print class medians\n",
    "print('*** Class 1 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==1]['Externalizing_Problems_Total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==1]['Externalizing_Problems_Total'].mean()))\n",
    "print('*** Class 2 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==2]['Externalizing_Problems_Total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==2]['Externalizing_Problems_Total'].mean()))\n",
    "print('*** Class 3 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==3]['Externalizing_Problems_Total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==3]['Externalizing_Problems_Total'].mean())),\n",
    "print('*** Class 4 Symptoms Median: {}; Mean: {} ***\\n'.format(symptom_df[symptom_df.ClusterID==4]['Externalizing_Problems_Total'].median(),\n",
    "                                                        symptom_df[symptom_df.ClusterID==4]['Externalizing_Problems_Total'].mean()))\n",
    "\n",
    "order = clus_cats\n",
    "pairs = pair_cats\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 3))\n",
    "\n",
    "sns.boxplot(x = 'ClusterID', y = 'Externalizing_Problems_Total', data = symptom_df,ax=ax, palette=\"blend:#f6b26b,#df6161\")\n",
    "sns.stripplot(y='Externalizing_Problems_Total', x='ClusterID',data = symptom_df, edgecolor='black', order=order, linewidth = 0.5, ax = ax,\n",
    "             palette=\"blend:#f6b26b,#df6161\")\n",
    "annotator = Annotator(ax=ax, pairs = pairs, data=symptom_df, x=x, y='Externalizing_Problems_Total', order=order)\n",
    "annotator.configure(test='Mann-Whitney', text_format='star', loc='inside')\n",
    "annotator.apply_and_annotate()\n",
    "plt.show()\n",
    "\n",
    "pairwise_gameshowell(data = symptom_df, dv = yvar, between = 'ClusterID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab93e73-025b-471f-9398-98daf5c15e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Symptom medians**')\n",
    "group_df[['ClusterID', 'diagnostic_group', 'Anxiety_Problems_Total', 'total_scared', 'tsc_total', 'Externalizing_Problems_Total']].groupby('ClusterID').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49bd46-1292-4285-a901-d2d73bce5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR correction\n",
    "fdr_table = pd.DataFrame(symp_pvals, columns = ['measure', 'pvalue'])\n",
    "fdr_table['fdr_passed'], fdr_table['fdr_pval'] = fdr(fdr_table['pvalue'])\n",
    "fdr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0950e0-7863-4d6f-8fe4-1da6e0ad37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "symp_corr = symptom_df.loc[:, [\"Internalizing_Problems_Total\", \"Externalizing_Problems_Total\", 'Anxiety_Problems_Total', 'Total_Problems_Total', 'tsc_anxiety', 'ri_ptsd_total']].dropna().corr()\n",
    "sns.heatmap(symp_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc962c7-98eb-4165-837b-20965865a05b",
   "metadata": {},
   "source": [
    "### Test group diffs in GSR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d38436-b6cf-4b2a-864e-7fb00a4ba8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr = pd.read_csv(analysis + '/GSR_data_2024-04-15.csv', index_col = 0)\n",
    "gsr_avg = gsr.groupby('Subject').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f69427-fb56-4e77-a467-c4a9d36ec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_group_df = pd.merge(gsr, group_df, on='Subject', how = 'inner').reset_index(drop=True)\n",
    "gsr_avg_df = pd.merge(gsr_avg.reset_index(), group_df, on='Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954d725-4125-4171-b589-39568f6fd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a77dab-95b0-48d1-bdd1-d230b872a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omnibus model\n",
    "gsr_data = gsr_group_df.dropna(axis=0, subset=['ClusterID', 'age_at_scan', 'sex', 'combined_income', 'Threat']).reset_index(drop=True)\n",
    "mod = sm.MixedLM.from_formula(\"Threat ~ ClusterID + Run_x + age_at_scan + sex + combined_income \", \n",
    "                groups=\"Subject\", data= gsr_data);\n",
    "aresults = mod.fit();\n",
    "print(aresults.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c644ab-d9bb-47ed-bed3-39a05a90cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_model = smf.ols(\"Threat ~ C(ClusterID) + sex + asr_age + combined_income + years_education \", data=gsr_avg_df).fit()\n",
    "table=sm.stats.anova_lm(gsr_model, type='3', robust='hc3')\n",
    "display(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880a1ed-6ddf-4740-b6ce-8700ca9ac7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (6, 3))\n",
    "\n",
    "sns.boxplot(x = 'ClusterID', y = 'Threat', data = gsr_data,ax=ax, palette=\"blend:#f6b26b,#df6161\")\n",
    "sns.stripplot(x = 'ClusterID', y = 'Threat', data = gsr_data, \n",
    "              edgecolor='black', order=order, linewidth = 0.5, ax = ax,\n",
    "              palette=\"blend:#f6b26b,#df6161\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434159b1-c5b3-49d0-bf0c-47171a36074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_tests(data = gsr_data, dv = 'Threat', between = 'ClusterID', effsize='cohen', padjust='fdr_bh', parametric=False, subject = 'Subject', return_desc=True).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0986a-45b2-4ada-93da-807288df5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_model = smf.ols(\"Safety ~ C(ClusterID) + sex + asr_age + combined_income + years_education \", data=gsr_avg_df).fit()\n",
    "table=sm.stats.anova_lm(gsr_model, type='3', robust='hc3')\n",
    "display(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b7c66-7bad-4f76-b17e-4798424a16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (6, 3))\n",
    "\n",
    "sns.boxplot(x = 'ClusterID', y = 'Safety', data = gsr_data,ax=ax, palette=\"blend:#f6b26b,#df6161\")\n",
    "sns.stripplot(x = 'ClusterID', y = 'Safety', data = gsr_data, edgecolor='black', order=order, linewidth = 0.5, ax = ax,\n",
    "             palette=\"blend:#f6b26b,#df6161\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9aeb8-e461-4db6-aa15-b54bd39d0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_tests(data = gsr_data, dv = 'Safety', between = 'ClusterID', effsize='cohen', padjust='fdr_bh', parametric=False, subject = 'Subject', return_desc=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d95a4-cb3f-46c4-8e15-d55678457d90",
   "metadata": {},
   "source": [
    "## Check for differences in counterbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1450db-b47c-44c9-89b3-5ce9b7c6b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import counterbalancing info\n",
    "cb1 = pd.read_csv(analysis + '/ShapesCounterbalancing_REDCap_7.10.24.csv').rename(columns = {'shapes_version':'redcap_record'})\n",
    "cb1['Subject'] = 'sub-' + cb1['record_id']\n",
    "\n",
    "cb2 = pd.read_csv(analysis + '/Shapes task versions (counterbalance) - Assignment.csv').drop(['Scan date', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5'], axis=1).rename(columns = {'Version':'gdoc_record'})\n",
    "cb2['Subject'] = 'sub-' + cb2['ID']\n",
    "\n",
    "cb3 = pd.read_csv(analysis + '/Shapes_Counterbalancing_fromEprime_2024-07-10.csv').drop('Unnamed: 0', axis=1).rename(columns = {'Counterbalancing':'eprime_file_record'})\n",
    "\n",
    "cb_m1 = pd.merge(cb1, cb2, on='Subject', how = 'outer')\n",
    "cb_m2 = pd.merge(cb_m1, cb3, on='Subject', how = 'outer')\n",
    "cb = cb_m2.drop(['record_id', 'ID'], axis=1).set_index('Subject').dropna(how = 'all', axis=0)\n",
    "\n",
    "cb['Final_Version'] = cb['gdoc_record']\n",
    "cb['Final_Version'].update(cb['redcap_record'])\n",
    "cb['Final_Version'].update(cb['eprime_file_record'])\n",
    "\n",
    "cb.to_csv(analysis + '/Shapes_Combined_Counterbalancing_n={}_{}.csv'.format(len(cb), today))\n",
    "print(analysis + '/Shapes_Combined_Counterbalancing_n={}_{}.csv'.format(len(cb), today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b39daa-86e6-426c-afc4-3fb159e8ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_df = pd.merge(cb.reset_index()[['Subject', 'Final_Version']], group_df, on='Subject', how = 'right')\n",
    "cb_df['Final_Version'] = cb_df['Final_Version'].astype(float)\n",
    "print(\"{} unique counterbalancing versions\".format(len(cb_df['Final_Version'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b18de-8b45-457f-8458-62185d2e18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df = cb_df[cb_df.Final_Version.isna()]\n",
    "print('{} participants are missing counterbalancing data'.format(len(nan_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0dc18c-ba4e-452f-bb63-51735b2e62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import anova\n",
    "\n",
    "# Do LPA variables differ as a function of counterbalancing?\n",
    "dvs = ['Early_Childhood_regr', 'Mid_Childhood_regr', 'Adolescence_regr','Adulthood_regr', 'hipp_tvs', \n",
    "       'amyg_tvs', 'AAL3_dACC_tvs','Mackey_25_tvs', 'Mackey_24_tvs', 'Mackey_32_14m_tvs']\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "for idx, yvar in enumerate(dvs):\n",
    "    printmd(\"**{}**\".format(yvar))\n",
    "    aov_mod = anova(data = cb_df, dv = yvar, between = 'Final_Version', ss_type = '2', detailed = True)\n",
    "    res_df = pd.concat([res_df, aov_mod.iloc[0:1,:]], axis=0)\n",
    "    display(aov_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb331f36-b3f1-45ed-a3fa-3765313cfb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR correction for multiple comparisons\n",
    "res_df['FDR Passed'], res_df['FDR p-val'] = fdr(res_df['p-unc'])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8822e-f95d-4155-bbe9-c1c97c81f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import chi2_independence, pairwise_corr\n",
    "\n",
    "# Does latent profile differ by counterbalancing?\n",
    "expected, observed, stats = chi2_independence(cb_df, x='Final_Version', y='ClusterID')\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefec75-c68e-4d0c-baef-484c563cf6f9",
   "metadata": {},
   "source": [
    "### Check correlations between covariates and dvs for clinical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d3d3e-5325-41f5-af29-b6d476a31264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are clinical symptoms and covariates correlated?\n",
    "corr_vars = [['scared_total_tranf', 'tsc_tranf', 'Externalizing_Problems_Total'], ['asr_age', 'combined_income', 'years_education']]\n",
    "\n",
    "symptom_df['combined_income'] = symptom_df['combined_income'].astype(float)\n",
    "symptom_df['years_education'] = symptom_df['years_education'].astype(float)\n",
    "\n",
    "pairwise_corr(data = symptom_df, columns = corr_vars, alternative = 'two-sided', method = 'spearman', padjust = 'fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873ca78-7e1a-4781-8726-5fe13c2c61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars = [['asr_age', 'combined_income', 'years_education'],['Early_Childhood_regr', 'Mid_Childhood_regr', \n",
    "             'Adolescence_regr','Adulthood_regr', 'hipp_tvs', 'amyg_tvs', 'AAL3_dACC_tvs','Mackey_25_tvs', \n",
    "             'Mackey_24_tvs', 'Mackey_32_14m_tvs']]\n",
    "\n",
    "group_df['combined_income'] = group_df['combined_income'].astype(float)\n",
    "group_df['years_education'] = group_df['years_education'].astype(float)\n",
    "\n",
    "pairwise_corr(data = group_df, columns = corr_vars, alternative = 'two-sided', method = 'spearman', padjust = 'fdr_bh').sort_values(by='p-corr', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f1454-b8c7-4a0d-a964-7d5e3fe3d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any of the following covariates differ as a function of latent profile?\n",
    "covars = ['asr_age', 'combined_income', 'years_education']\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "for idx, yvar in enumerate(covars):\n",
    "    printmd(\"**{}**\".format(yvar))\n",
    "    aov_mod = anova(data = symptom_df, dv = yvar, between = 'ClusterID', ss_type = '2', detailed = True)\n",
    "    res_df = pd.concat([res_df, aov_mod.iloc[0:1,:]], axis=0)\n",
    "    display(aov_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be822a8-f71b-478c-ab3f-d3766d664840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR correction for multiple comparisons\n",
    "res_df['FDR Passed'], res_df['FDR p-val'] = fdr(res_df['p-unc'])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec4cfe-f153-4a66-846d-8ebf147e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does sex differ between latent profiles?\n",
    "expected, observed, stats = chi2_independence(cb_df, x='sex', y='ClusterID')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618621de-5d9e-485b-94e0-7b766615fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do dvs differ by sex?\n",
    "dvs = ['scared_total_tranf', 'tsc_tranf', 'Externalizing_Problems_Total']\n",
    "\n",
    "for idx, yvar in enumerate(dvs):\n",
    "    printmd(\"**{}**\".format(yvar))\n",
    "    aov_mod = pairwise_tests(data = symptom_df, dv = yvar, between = 'sex')\n",
    "    res_df = pd.concat([res_df, aov_mod.iloc[0:1,:]], axis=0)\n",
    "    display(aov_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c3e98-7718-4fed-8c22-3d8c764c6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = symptom_df[['Early_Childhood_regr', 'Mid_Childhood_regr', 'Adolescence_regr','Adulthood_regr', \n",
    "                      'hipp_tvs', 'amyg_tvs', 'AAL3_dACC_tvs','Mackey_25_tvs', 'Mackey_24_tvs', \n",
    "                      'Mackey_32_14m_tvs', 'asr_age', 'combined_income', 'years_education', \n",
    "                      'scared_total_tranf', 'tsc_tranf', 'Externalizing_Problems_Total']].astype(float)\n",
    "corr_df = corr_df.rename(columns = {'scared_total_tranf':'SCAARED Anxiety Symptoms', 'tsc_tranf':'TSC-40 Trauma-Related Symptoms', 'Externalizing_Problems_Total':'ASR Externalizing Problems', 'combined_income': 'Combined Family Income', 'asr_age':'Age at Symptom Questionnaires', 'years_education': 'Years of Education'})\n",
    "\n",
    "corr_df.columns = corr_df.columns.str.replace('_', ' ').str.replace('tvs', 'Activation (Threat vs. Safety)').str.replace('regr', 'Adversity').str.replace('Mackey', 'vmPFC Area').str.replace('AAL3', '').str.replace('hipp', 'Hippocampus').str.replace('amyg', 'Amygdala').str.replace('Mid', 'Middle')\n",
    "corr_df_img = corr_df.corr(method = 'spearman').round(3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11,9))\n",
    "sns.heatmap(corr_df_img, vmin=-1, vmax=1, annot = True, annot_kws = {'fontsize':8})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
